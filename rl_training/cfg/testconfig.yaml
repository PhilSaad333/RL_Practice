# grpo_gsm8k_qwen2.yaml   –  starter settings for smoke-tests
# ----------------------------------------------------
# Anything in this file is passed verbatim to RolloutCollector via cfg.
# The GRPO trainer will later read the same file and use only what it needs.



# rl_configs/rl_qwen2.yaml
backbone: Qwen/Qwen2.5-1.5B
eval_backbone: qwen2_5_15


# -------------- rollout collector ---------------- #

# ---- rollout collection ----
rollout_batch_size: 16
num_generations: 8

# VLLM settings (default: enabled for better performance)
# Set use_vllm: false to use standard rollout collection instead
use_vllm: false  # Disabled for A100 - CUDA multiprocessing conflict
vllm_reload_every: 5                   # Reload model weights every N steps for online training
vllm_gpu_memory_utilization: 0.25     # Reserve 25% GPU memory for VLLM, 75% for training

# Recompute logprobs: teacher-forcing forward micro-batch size
tf_micro_batch: 8

# Write rollouts.jsonl every N collect_batch() calls (0 = never)
save_rollouts_every: 0



buffer_size       : 32    # REDUCED for A100 (40GB) vs H100 (80GB)
microbatch_size   : 2    # Optimized for A100 40GB memory
# grad_accum_steps automatically computed: buffer_size / (world_size * microbatch_size)
# For 1 GPU: 16 / (1 * 2) = 8 microbatches

# Optimized for single A100 (40GB) vs original 2xH100 (160GB) setup

ppo_epochs        : 1 #3   # K: number of updates per rollout-collection step.
max_new_tokens    : 100   # Reasonable length for GSM8K problems
temperature       : 0.7
#top_p             : 0.95 #remove 

eval_frac: 0.01        
eval_batch_size: 64
eval_temperature: 0.7


reward_var_thresh : 0.01
reject_all_zero   : true
reject_all_max    : true

reward_fns:
  - tag_pref
  #- tag_math_correct

scheduler:
  name          : mix_passrate
  dataset_name  : gsm8k_r1_template
  split         : "train"
  ema_alpha     : 0.01
  boundaries    : [0.2, 0.8]
  sample_weights: [1, 1, 1]

# ------------------ trainer (GRPO) --------------- #
lr               : 1.0e-6
clip_eps         : 0.2
clip_+           : 0.2 #asymmetric clipping

cfg["kl_beta"]   : 0.0 # If zero only computes KL with no grad for logging

ent_coef         : 0.0            # future entropy bonus knob
grad_clip        : 1.0
bf16             : true

gradient_checkpointing : true

lr_scheduler: "const" # 'const' or 'cosine'

save_every: 2
total_steps: 4


entropy_probe:
  every: 0          # DISABLED for eval debugging
  sketch_r: 0         # 0 = off for now
  out_dir: entropy_probes


gns_probe:
  enabled: false    # Enable/disable in-loop gradient noise scale tracking
  # 
  # The GNS probe estimates the critical batch size for training by measuring
  # the ratio of gradient noise to signal. It runs with zero extra forward/backward
  # passes, piggybacking on your existing training gradients.
  #
  # Metrics produced:
  #   - gns_mu: Gradient noise scale (noise/signal ratio at micro-batch level)
  #   - Bsimple_from_mu: Estimated critical batch size (where noise ≈ signal)
  #   - gns_ess: Effective sample size (accounts for Dr-GRPO weighted losses)
  #   - gns_consistency_ratio: Validation metric (should ≈ 1.0 after warmup)
  #   - gns_G2: Global gradient squared norm
  #   - gns_tr_sigma: Trace of gradient covariance
  #
  # Interpretation:
  #   - If your batch size < Bsimple_from_mu: gradient noise is high, consider larger batches
  #   - If your batch size >> Bsimple_from_mu: diminishing returns, could use smaller batches
  #   - gns_ess < (B × G) shows impact of unequal Dr-GRPO weights on variance reduction
