# testconfig.yaml   –  starter settings for smoke-tests
# ----------------------------------------------------
# Anything in this file is passed verbatim to RolloutCollector via cfg.
# The GRPO trainer will later read the same file and use only what it needs.

backbone: Qwen/Qwen2-0.5B
eval_backbone: qwen2
#backbone: microsoft/phi-2
#eval_backbone: phi2

# -------------- rollout collector ---------------- #
rollout_batch_size: 8
num_generations   : 4 #8   # G: number of generations per prompt
buffer_size       : 8 #2048   # total number of prompts in buffer (multiple of microbatch_size*grad_accum_steps)
microbatch_size   : 2   # B: prompts used for each gradient checkpointing steps
grad_accum_steps  : 2 #8   # ga_steps: total number of prompts per update batch = ga_step*B
ppo_epochs        : 1 #3   # K: number of updates per rollout-collection step.
max_new_tokens    : 128
temperature       : 1.0
#top_p             : 0.95 #remove 

eval_every: 24        # ← run eval every 48 optimiser steps
eval_frac: 0.01
eval_cfg:             # (reserved for future – temperature, top-p, etc.)
  temperature: 0.7
  top_p: 1.0
  batch_size: 12
  subset_frac: 0.3


reward_var_thresh : 0.01
reject_all_zero   : False
reject_all_max    : False

reward_fns:
  - tag_pref
  #- tag_math_correct

scheduler:
  name          : mix_passrate
  dataset_name  : gsm8k_latex
  split         : "train"
  ema_alpha     : 0.05
  boundaries    : [0.2, 0.8]
  sample_weights: [1, 1, 1]

# ------------------ trainer (GRPO) --------------- #
lr               : 2.0e-5
clip_eps         : 0.2
clip_+           : 0.2 #asymmetric clipping
#kl_beta          : 0.05
#kl_target        : 0.1
#max_kl           : 0.15
ent_coef         : 0.0            # future entropy bonus knob
grad_clip        : 1.0
bf16             : true

gradient_checkpointing : true

save_every: 5
total_steps: 10

