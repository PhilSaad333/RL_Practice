# grpo_gsm8k_qwen2.yaml   â€“  starter settings for smoke-tests
# ----------------------------------------------------
# Anything in this file is passed verbatim to RolloutCollector via cfg.
# The GRPO trainer will later read the same file and use only what it needs.



# rl_configs/rl_qwen2.yaml
#backbone: Qwen/Qwen2-0.5B
backbone: Qwen/Qwen2.5-1.5B
eval_backbone: qwen2_5_15
#eval_backbone: qwen2
#lora_ckpt: /content/drive/.../qwen2_gsm8k_lora      # << your SFT output dir


# -------------- rollout collector ---------------- #

# ---- rollout collection ----
rollout_batch_size: 16
num_generations: 8

# Recompute logprobs: teacher-forcing forward micro-batch size
tf_micro_batch: 8

# Write rollouts.jsonl every N collect_batch() calls (0 = never)
save_rollouts_every: 0



buffer_size       : 32    # REDUCED for memory debugging - was 32
microbatch_size   : 2    # REDUCED for memory debugging - was 4  
grad_accum_steps  : 16    # REDUCED for memory debugging - was 8

# Above gives much smaller memory footprint for debugging

ppo_epochs        : 1 #3   # K: number of updates per rollout-collection step.
max_new_tokens    : 100   # REDUCED for memory debugging - was 200
temperature       : 0.7
#top_p             : 0.95 #remove 

eval_every: 0        
eval_frac: 0.01        
eval_batch_size: 128
eval_temperature: 0.7


reward_var_thresh : 0.01
reject_all_zero   : true
reject_all_max    : true

reward_fns:
  - tag_pref
  #- tag_math_correct

scheduler:
  name          : mix_passrate
  dataset_name  : gsm8k_r1_template
  split         : "train"
  ema_alpha     : 0.01
  boundaries    : [0.2, 0.8]
  sample_weights: [1, 1, 1]

# ------------------ trainer (GRPO) --------------- #
lr               : 1.0e-6
clip_eps         : 0.2
clip_+           : 0.2 #asymmetric clipping

cfg["kl_beta"]   : 0.0 # If zero only computes KL with no grad for logging

ent_coef         : 0.0            # future entropy bonus knob
grad_clip        : 1.0
bf16             : true

gradient_checkpointing : true

lr_scheduler: "const" # 'const' or 'cosine'

save_every: 1
total_steps: 2


entropy_probe:
  every: 0          # DISABLED for debugging DDP hang
  sketch_r: 0         # 0 = off for now
  out_dir: entropy_probes


gns_probe:
  every: 0          # DISABLED for debugging DDP hang
  small_B: 8         # prompts in the small batch
  large_B: 16         # prompts in the large batch (reduced for debugging with small buffer)
  ema: 0.9           # EWMA smoothing for norm^2 measurements
