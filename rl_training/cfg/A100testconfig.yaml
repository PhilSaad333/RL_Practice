# A100testconfig.yaml - Optimized for single A100 40GB testing
# ================================================================
# This config is specifically tuned for single A100 40GB GPU instances
# Reduces memory usage compared to testconfig.yaml for dual/larger GPUs

# Model configuration
backbone: Qwen/Qwen2.5-1.5B
eval_backbone: qwen2_5_15

# -------------- Rollout Collection (Single A100 Optimized) ---------------- #

# Batch sizes for generation (reduced for A100 40GB)
rollout_batch_size: 12    # Halved from 24 for single A100
num_generations: 8        # Keep at 8

# VLLM disabled due to dependency conflicts
use_vllm: false
vllm_reload_every: 5
vllm_gpu_memory_utilization: 0.25

# Teacher-forcing configuration (reduced for memory)
tf_micro_batch: 8         # Keep at 8 for now

# Data saving
save_rollouts_every: 0    # 0 = never save

# -------------- Training Configuration (Single A100 Optimized) ---------------- #

# Buffer and batch sizes (optimized for single A100 40GB)
buffer_size: 32           # Increased for better GNS data collection
microbatch_size: 2        # Keep at 2
# grad_accum_steps = buffer_size / (world_size * microbatch_size) = 32 / (1 * 2) = 16

# PPO configuration
ppo_epochs: 1             # Single epoch per buffer
max_new_tokens: 100       # Reduced from 150 to save memory
temperature: 0.7          # Sampling temperature

# Evaluation configuration
eval_frac: 0.01           # Small fraction for testing
eval_batch_size: 64       # Keep evaluation batch size
eval_temperature: 0.7

# Reward configuration
reward_var_thresh: 0.01
reject_all_zero: true
reject_all_max: true

reward_fns:
  - tag_pref              # Primary reward function

# Scheduler configuration
scheduler:
  name: mix_passrate
  dataset_name: gsm8k_r1_template
  split: "train"
  ema_alpha: 0.01
  boundaries: [0.2, 0.8]
  sample_weights: [1, 1, 1]

# ------------------ GRPO Trainer Configuration ---------------- #

# Learning rate and optimization
lr: 1.0e-6                # Learning rate
clip_eps: 0.2             # PPO clipping epsilon
clip_+: 0.2               # Asymmetric clipping
cfg["kl_beta"]: 0.0       # KL penalty (0 = compute for logging only)
ent_coef: 0.0             # Entropy coefficient
grad_clip: 1.0            # Gradient clipping norm

# Training settings
bf16: true                # Use bfloat16 precision
gradient_checkpointing: true
lr_scheduler: "const"     # Constant learning rate

# Checkpoint configuration (Entropy probe testing)
save_every: 1             # Save every step for testing
total_steps: 2            # Just 2 steps for quick entropy probe testing

# -------------- Diagnostic Probes ---------------- #

# Entropy probe (disabled)
entropy_probe:
  every: 0                # 0 = disabled
  sketch_r: 0
  out_dir: entropy_probes

# Gradient Noise Scale probe (DISABLED for entropy probe testing)
gns_probe:
  enabled: false          # Disabled to focus on entropy probe testing
  window_size: 8          # Number of steps to store for variance computation
  ema_alpha: 0.1          # EMA smoothing factor
  debug: false            # Print debug information for testing
  
# Entropy Probe (ENABLED for first-order entropy change analysis)
entropy_probe:
  enabled: true           # Enable first-order entropy change analysis
  debug: true             # Print debug information
  max_sequences: 200      # Memory safety limit for A100 testing
  store_full_kernel: true # Store complete K_1(t,t') Fisher kernel matrix
  save_every: 1           # Save detailed data every step for testing
  # 
  # Testing the new entropy probe implementation that computes:
  # δH = -η * (1/(B*G)) * Σ (S(t) - S̄) * K_1(t,t') * A(t') * (1/L_max)
  # Where K_1(t,t') is the Fisher kernel with Adam conditioning.
  # This requires per-sequence gradient computation (expensive but accurate).