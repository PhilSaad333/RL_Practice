{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy Convergence Analysis\n",
    "\n",
    "Comparing basic_entropy_sum vs diag_rb_entropy_sum convergence with batch size.\n",
    "\n",
    "**Research Question**: Does RB entropy provide better (lower variance) estimates than basic entropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Load the data\n",
    "data_file = \"data/entropy_study_1.json\"\n",
    "print(f\"Loading data from: {data_file}\")\n",
    "\n",
    "with open(data_file, 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(results['per_sequence_data'])} sequences\")\n",
    "print(f\"Experiment info: {results['experiment_info']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Inspection\n",
    "\n",
    "Let's first understand what we're working with and check for data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract per-sequence data\n",
    "per_seq_data = results['per_sequence_data']\n",
    "df = pd.DataFrame(per_seq_data)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nColumns:\", list(df.columns))\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for data quality issues\n",
    "print(\"=== DATA QUALITY CHECKS ===\")\n",
    "print(f\"Total sequences: {len(df)}\")\n",
    "print(f\"Missing basic_entropy_sum: {df['basic_entropy_sum'].isna().sum()}\")\n",
    "print(f\"Missing diag_rb_entropy_sum: {df['diag_rb_entropy_sum'].isna().sum()}\")\n",
    "print(f\"Zero basic_entropy_sum: {(df['basic_entropy_sum'] == 0).sum()}\")\n",
    "print(f\"Zero diag_rb_entropy_sum: {(df['diag_rb_entropy_sum'] == 0).sum()}\")\n",
    "print(f\"Very small basic_entropy_sum (<0.01): {(df['basic_entropy_sum'] < 0.01).sum()}\")\n",
    "print(f\"Very small diag_rb_entropy_sum (<0.01): {(df['diag_rb_entropy_sum'] < 0.01).sum()}\")\n",
    "\n",
    "print(\"\\n=== BASIC ENTROPY STATISTICS ===\")\n",
    "print(df['basic_entropy_sum'].describe())\n",
    "\n",
    "print(\"\\n=== RB ENTROPY STATISTICS ===\")\n",
    "print(df['diag_rb_entropy_sum'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data is shuffled or ordered\n",
    "print(\"=== DATA ORDERING CHECK ===\")\n",
    "print(\"First 10 basic entropy values:\")\n",
    "print(df['basic_entropy_sum'].head(10).tolist())\n",
    "print(\"\\nLast 10 basic entropy values:\")\n",
    "print(df['basic_entropy_sum'].tail(10).tolist())\n",
    "\n",
    "# Check correlation between index and entropy (would indicate ordering)\n",
    "index_corr_basic = np.corrcoef(range(len(df)), df['basic_entropy_sum'])[0,1]\n",
    "index_corr_rb = np.corrcoef(range(len(df)), df['diag_rb_entropy_sum'])[0,1]\n",
    "print(f\"\\nCorrelation between index and basic entropy: {index_corr_basic:.4f}\")\n",
    "print(f\"Correlation between index and RB entropy: {index_corr_rb:.4f}\")\n",
    "if abs(index_corr_basic) > 0.1 or abs(index_corr_rb) > 0.1:\n",
    "    print(\"‚ö†Ô∏è WARNING: Data might be ordered, which could affect batch analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Convergence Analysis\n",
    "\n",
    "Now let's carefully implement the batch convergence analysis, being explicit about what we're computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_batch_convergence(basic_vals, rb_vals, batch_sizes, shuffle_data=False):\n",
    "    \"\"\"\n",
    "    Analyze how batch means and their variance change with batch size.\n",
    "    \n",
    "    For each batch size B:\n",
    "    1. Divide data into batches of size B\n",
    "    2. Compute mean of each batch\n",
    "    3. Compute mean and std of the batch means\n",
    "    \n",
    "    The key insight:\n",
    "    - Mean of batch means ‚âà overall mean (should be similar across batch sizes)\n",
    "    - Std of batch means should decrease as B increases (law of large numbers)\n",
    "    - RB entropy should have lower std than basic entropy (variance reduction)\n",
    "    \"\"\"\n",
    "    \n",
    "    if shuffle_data:\n",
    "        # Shuffle to remove any ordering effects\n",
    "        indices = np.random.permutation(len(basic_vals))\n",
    "        basic_vals = basic_vals[indices]\n",
    "        rb_vals = rb_vals[indices]\n",
    "        print(\"üîÄ Data shuffled to remove ordering effects\")\n",
    "    \n",
    "    N = len(basic_vals)\n",
    "    print(f\"Total samples: {N}\")\n",
    "    \n",
    "    # Overall statistics for reference\n",
    "    overall_basic_mean = np.mean(basic_vals)\n",
    "    overall_rb_mean = np.mean(rb_vals)\n",
    "    print(f\"Overall basic entropy mean: {overall_basic_mean:.4f}\")\n",
    "    print(f\"Overall RB entropy mean: {overall_rb_mean:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for B in batch_sizes:\n",
    "        n_batches = N // B\n",
    "        if n_batches < 2:\n",
    "            print(f\"Batch size B={B}: Skipping (would give <2 batches)\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Batch size B={B}: {n_batches} complete batches\")\n",
    "        \n",
    "        # Compute batch means\n",
    "        basic_batch_means = []\n",
    "        rb_batch_means = []\n",
    "        \n",
    "        for i in range(n_batches):\n",
    "            start_idx = i * B\n",
    "            end_idx = start_idx + B\n",
    "            \n",
    "            basic_batch_mean = np.mean(basic_vals[start_idx:end_idx])\n",
    "            rb_batch_mean = np.mean(rb_vals[start_idx:end_idx])\n",
    "            \n",
    "            basic_batch_means.append(basic_batch_mean)\n",
    "            rb_batch_means.append(rb_batch_mean)\n",
    "        \n",
    "        # Statistics across batches\n",
    "        basic_mean = np.mean(basic_batch_means)\n",
    "        basic_std = np.std(basic_batch_means, ddof=1)\n",
    "        \n",
    "        rb_mean = np.mean(rb_batch_means)\n",
    "        rb_std = np.std(rb_batch_means, ddof=1)\n",
    "        \n",
    "        # Variance reduction\n",
    "        var_reduction = (basic_std**2 - rb_std**2) / basic_std**2 * 100\n",
    "        \n",
    "        print(f\"  Basic entropy - Mean: {basic_mean:.6f}, Std: {basic_std:.6f}\")\n",
    "        print(f\"  RB entropy    - Mean: {rb_mean:.6f}, Std: {rb_std:.6f}\")\n",
    "        print(f\"  Variance reduction: {var_reduction:.1f}%\")\n",
    "        \n",
    "        # Check if means are suspiciously identical\n",
    "        if abs(basic_mean - overall_basic_mean) < 1e-10:\n",
    "            print(f\"  ‚ö†Ô∏è WARNING: Batch mean is EXACTLY equal to overall mean (to 10 decimal places)\")\n",
    "        \n",
    "        print(f\"  Standard error of mean: Basic={basic_std/np.sqrt(n_batches):.6f}, RB={rb_std/np.sqrt(n_batches):.6f}\")\n",
    "        print()\n",
    "        \n",
    "        results.append({\n",
    "            'batch_size': B,\n",
    "            'n_batches': n_batches,\n",
    "            'basic_mean': basic_mean,\n",
    "            'basic_std': basic_std,\n",
    "            'rb_mean': rb_mean,\n",
    "            'rb_std': rb_std,\n",
    "            'var_reduction': var_reduction,\n",
    "            'basic_batch_means': basic_batch_means.copy(),\n",
    "            'rb_batch_means': rb_batch_means.copy()\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run analysis\n",
    "basic_entropies = df['basic_entropy_sum'].values\n",
    "rb_entropies = df['diag_rb_entropy_sum'].values\n",
    "batch_sizes = [32, 64, 128, 256, 512]\n",
    "\n",
    "print(\"=== ANALYSIS WITH ORIGINAL DATA ORDER ===\")\n",
    "results_original = analyze_batch_convergence(basic_entropies, rb_entropies, batch_sizes, shuffle_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== ANALYSIS WITH SHUFFLED DATA ===\")\n",
    "np.random.seed(42)  # For reproducibility\n",
    "results_shuffled = analyze_batch_convergence(basic_entropies, rb_entropies, batch_sizes, shuffle_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive plots\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "# Use the shuffled results for plotting (more reliable)\n",
    "results = results_shuffled\n",
    "batch_sizes_plot = [r['batch_size'] for r in results]\n",
    "\n",
    "# Plot 1: Batch means convergence\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "basic_means = [r['basic_mean'] for r in results]\n",
    "rb_means = [r['rb_mean'] for r in results]\n",
    "plt.plot(batch_sizes_plot, basic_means, 'o-', label='Basic Entropy', linewidth=2, markersize=8)\n",
    "plt.plot(batch_sizes_plot, rb_means, 's-', label='RB Entropy', linewidth=2, markersize=8)\n",
    "plt.axhline(np.mean(basic_entropies), color='blue', linestyle='--', alpha=0.5, label='True Basic Mean')\n",
    "plt.axhline(np.mean(rb_entropies), color='orange', linestyle='--', alpha=0.5, label='True RB Mean')\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Mean of Batch Means')\n",
    "plt.title('Convergence of Batch Means')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xscale('log', base=2)\n",
    "\n",
    "# Plot 2: Standard deviation (convergence rate)\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "basic_stds = [r['basic_std'] for r in results]\n",
    "rb_stds = [r['rb_std'] for r in results]\n",
    "plt.plot(batch_sizes_plot, basic_stds, 'o-', label='Basic Entropy', linewidth=2, markersize=8)\n",
    "plt.plot(batch_sizes_plot, rb_stds, 's-', label='RB Entropy', linewidth=2, markersize=8)\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Std of Batch Means')\n",
    "plt.title('Convergence Rate (Lower = Better)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xscale('log', base=2)\n",
    "plt.yscale('log')\n",
    "\n",
    "# Plot 3: Variance reduction\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "var_reductions = [r['var_reduction'] for r in results]\n",
    "plt.plot(batch_sizes_plot, var_reductions, 'o-', color='green', linewidth=2, markersize=8)\n",
    "plt.axhline(0, color='black', linestyle='--', alpha=0.5)\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Variance Reduction (%)')\n",
    "plt.title('RB Entropy Variance Reduction')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xscale('log', base=2)\n",
    "\n",
    "# Plot 4: Distribution of basic entropies\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "plt.hist(basic_entropies, bins=50, alpha=0.7, density=True, color='blue', label='Basic Entropy')\n",
    "mean_basic = np.mean(basic_entropies)\n",
    "std_basic = np.std(basic_entropies)\n",
    "plt.axvline(mean_basic, color='red', linestyle='--', label=f'Mean: {mean_basic:.3f}')\n",
    "plt.axvline(mean_basic + std_basic, color='red', linestyle=':', alpha=0.7)\n",
    "plt.axvline(mean_basic - std_basic, color='red', linestyle=':', alpha=0.7)\n",
    "plt.xlabel('Basic Entropy Sum')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Basic Entropy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: Distribution of RB entropies\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "plt.hist(rb_entropies, bins=50, alpha=0.7, density=True, color='green', label='RB Entropy')\n",
    "mean_rb = np.mean(rb_entropies)\n",
    "std_rb = np.std(rb_entropies)\n",
    "plt.axvline(mean_rb, color='red', linestyle='--', label=f'Mean: {mean_rb:.3f}')\n",
    "plt.axvline(mean_rb + std_rb, color='red', linestyle=':', alpha=0.7)\n",
    "plt.axvline(mean_rb - std_rb, color='red', linestyle=':', alpha=0.7)\n",
    "plt.xlabel('RB Entropy Sum')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of RB Entropy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Scatter plot\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "plt.scatter(basic_entropies, rb_entropies, alpha=0.5, s=20)\n",
    "plt.xlabel('Basic Entropy Sum')\n",
    "plt.ylabel('RB Entropy Sum')\n",
    "plt.title('Basic vs RB Entropy Correlation')\n",
    "corr = np.corrcoef(basic_entropies, rb_entropies)[0,1]\n",
    "plt.text(0.05, 0.95, f'Correlation: {corr:.3f}', transform=ax6.transAxes, \n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Investigation of Near-Zero Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the near-zero entropy values\n",
    "print(\"=== INVESTIGATING NEAR-ZERO VALUES ===\")\n",
    "\n",
    "# Find sequences with very low entropy\n",
    "low_basic_mask = basic_entropies < 0.1\n",
    "low_rb_mask = rb_entropies < 0.1\n",
    "\n",
    "print(f\"Sequences with basic entropy < 0.1: {low_basic_mask.sum()}\")\n",
    "print(f\"Sequences with RB entropy < 0.1: {low_rb_mask.sum()}\")\n",
    "\n",
    "if low_basic_mask.sum() > 0:\n",
    "    print(\"\\nExamples of low basic entropy sequences:\")\n",
    "    low_basic_indices = np.where(low_basic_mask)[0][:5]\n",
    "    for idx in low_basic_indices:\n",
    "        seq = per_seq_data[idx]\n",
    "        print(f\"  Index {idx}: basic={seq['basic_entropy_sum']:.6f}, rb={seq['diag_rb_entropy_sum']:.6f}\")\n",
    "        print(f\"    Response length: {seq['response_length_tokens']} tokens\")\n",
    "        print(f\"    Response text: '{seq['response_text'][:100]}...'\")\n",
    "        print()\n",
    "\n",
    "# Check if low entropy correlates with short responses\n",
    "response_lengths = df['response_length_tokens'].values\n",
    "print(f\"Correlation between basic entropy and response length: {np.corrcoef(basic_entropies, response_lengths)[0,1]:.3f}\")\n",
    "print(f\"Correlation between RB entropy and response length: {np.corrcoef(rb_entropies, response_lengths)[0,1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== FINAL SUMMARY ===\")\n",
    "print(f\"Total sequences analyzed: {len(df)}\")\n",
    "print(f\"Basic entropy: mean={np.mean(basic_entropies):.4f}, std={np.std(basic_entropies):.4f}\")\n",
    "print(f\"RB entropy: mean={np.mean(rb_entropies):.4f}, std={np.std(rb_entropies):.4f}\")\n",
    "print(f\"Correlation: {np.corrcoef(basic_entropies, rb_entropies)[0,1]:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Variance reduction by batch size:\")\n",
    "for r in results_shuffled:\n",
    "    print(f\"  B={r['batch_size']:>3}: {r['var_reduction']:>6.1f}% (Basic std: {r['basic_std']:.4f}, RB std: {r['rb_std']:.4f})\")\n",
    "\n",
    "print()\n",
    "avg_var_reduction = np.mean([r['var_reduction'] for r in results_shuffled])\n",
    "print(f\"Average variance reduction: {avg_var_reduction:.1f}%\")\n",
    "\n",
    "if avg_var_reduction > 30:\n",
    "    print(\"‚úÖ RB entropy shows significant variance reduction!\")\n",
    "elif avg_var_reduction > 10:\n",
    "    print(\"‚ö†Ô∏è RB entropy shows moderate variance reduction.\")\n",
    "else:\n",
    "    print(\"‚ùå RB entropy shows minimal variance reduction.\")\n",
    "\n",
    "# Check for the \"exactly identical means\" issue\n",
    "basic_means = [r['basic_mean'] for r in results_shuffled]\n",
    "rb_means = [r['rb_mean'] for r in results_shuffled]\n",
    "\n",
    "basic_mean_range = max(basic_means) - min(basic_means)\n",
    "rb_mean_range = max(rb_means) - min(rb_means)\n",
    "\n",
    "print(f\"\\nRange of batch means across different batch sizes:\")\n",
    "print(f\"  Basic entropy: {basic_mean_range:.8f}\")\n",
    "print(f\"  RB entropy: {rb_mean_range:.8f}\")\n",
    "\n",
    "if basic_mean_range < 1e-6 or rb_mean_range < 1e-6:\n",
    "    print(\"‚ö†Ô∏è Means are suspiciously identical across batch sizes - this suggests a potential issue with the analysis.\")\n",
    "else:\n",
    "    print(\"‚úÖ Batch means show reasonable variation across batch sizes.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}