Fisher Kernel Study Plan
========================

Context
-------
We want tools for analyzing how an RL optimizer step affects log-probabilities of individual sequences. The objective is to approximate the Fisher kernel interaction between an "update" batch U (with rewards/advantages) and an evaluation batch E (arbitrary, potentially custom prompts/responses) while respecting AdamW preconditioning but ignoring momentum terms.

Key Definitions
---------------
- For a sequence X with prompt P, let S(X|P) = log pi(X|P).
- Classic REINFORCE SGD update produces Δ log pi(X|P) proportional to Σ_{(X',P')∈U} K((X,P), (X',P')) * A(X'|P'), where K is the Fisher kernel Σ_α ∂_α S(X|P) ∂_α S(X'|P').
- In AdamW, the effective kernel includes preconditioning. We will model a simplified variant that uses the instantaneous diagonal preconditioner (sqrt(v̂)+ε)^{-1} but omits momentum.

High-Level Workflow
-------------------
1. Load checkpoint + optimizer state with the same helpers already used in entropy experiments (model_loader, update_vector.compute_update_vector).
2. Sample (or load) E and U batches using SequenceProcessor utilities so that batching aligns with existing entropy probes.
3. For each U microbatch:
   - Compute per-sequence gradients of S(X|P) with respect to model parameters.
   - Apply Adam diagonal preconditioning (using stored exp_avg_sq) to obtain preconditioned gradients ĝ.
4. For each E microbatch:
   - Compute gradients of S(X|P) as above.
   - Contract with stored ĝ blocks to obtain Fisher kernel entries K_block and influence contributions Δ log pi_E = K_block @ A_U.
   - Stream results to avoid holding the full K matrix unless explicitly requested.
5. Aggregate diagnostics:
   - Per-sequence Δ log pi for E.
   - Attribution summary (top contributing U sequences per E sequence, cosine similarities, norm statistics).
   - Optional selected K submatrices for qualitative inspection.

Design Considerations
---------------------
- Reuse SequenceProcessor + batching logic from delta_entropy_true/approx to avoid code drift.
- Build around microbatch loops so memory footprint stays manageable (batch sizes ≈512).
- Provide toggles for what to store (full K vs. aggregate), and for which E source to use (model-generated, dataset, or manual list).
- Integrate with DetailedLogger for debugging and reproducibility.

Proposed Module Skeleton
------------------------
File: entropy_experiments/fisher_kernel.py

Classes / Functions:
- FisherKernelPlan dataclass: flags for capturing full K, choosing E source, batch sizes, etc.
- FisherKernelRunner(config): handles checkpoint loading, batch preparation, gradient collection, preconditioning, and diagnostics assembly.
- _collect_gradients(batch, microbatch_size): returns list of per-sequence gradients (sparsified or low-rank handle) together with metadata.
- _apply_adam_preconditioner(grads, optimizer_state): scales gradient tensors in place.
- _contract_blocks(E_grads, U_grads, advantages, capture_full): yields influence vectors and optional K blocks.
- save_results(...): dump JSON/NPZ outputs mirroring run_entropy_experiments structure.

Outputs & Artifacts
-------------------
- results.json containing per-sequence Δ log pi, influence metadata, configuration snapshot, and optional stored K slices.
- plan.json recording toggles (full kernel capture, microbatch sizes, etc.).
- Optional notebook helpers in results/notebooks to visualize heatmaps and influence distributions.

Execution Flow
--------------
1. CLI (to be added later) parses config, creates FisherKernelPlan, and selects output directory.
2. FisherKernelRunner loads model/optimizer, prepares U/E batches.
3. Runner iterates over microbatches, collects gradients, applies preconditioning, computes contributions, and aggregates diagnostics.
4. Results are serialized for downstream analysis (histograms, qualitative inspection, comparison with actual Δ log pi observed during training).

Next Steps
----------
- Draft module skeleton with placeholder functions mirroring this plan.
- Confirm gradient APIs in SequenceProcessor support required per-sequence differentiation efficiently; extend if necessary.
- Prototype on small batches to validate memory usage and check alignment between predicted Δ log pi and actual entropy probe measurements.


Custom E Overrides
------------------
- Support injecting hand-crafted evaluation batches. Provide a helper (e.g., CustomSample) that emits payloads matching SequenceProcessor outputs (tokens, text, logprobs) so the Fisher kernel runner can ingest them without extra glue.
- Use cases: (1) select prompts from dataset with curated responses; (2) author new prompts/responses to probe specific behaviors (e.g., low-probability tokens).
- Keep runner interfaces flexible: plan should accept an optional E override payload or callback.

Sample Generator Blueprint
--------------------------
- Create utils/sample_generator.py as the hub for sampling update/eval batches without initializing EntropyMeasurements; it should own checkpoint/model/tokenizer loading and orchestrate SequenceProcessor usage.
- Introduce dataclasses:
  * SequenceRecord capturing prompt/response tokens, decoded text, per-token logprobs/logqs/entropies, rewards, advantages, provenance (global_prompt_id, dataset split, batch indices, stable sequence_id).
  * GeneratedBatch wrapping a list of SequenceRecord, raw tensors (prompt/response token tensors, masks, rewards, advantages), sampling diagnostics, and lookup helpers for sequence ids or prompt groupings.
- SampleGenerator APIs:
  * generate_update_batch(batch_size_prompts, completions_per_prompt, dataset_split, seed, reward_cfg, advantage_cfg) to mirror RL update sampling; produces rich metadata and ids like U-000-01.
  * generate_evaluation_batch(batch_size_prompts, completions_per_prompt=1, with_replacement=True, dataset_split, seed) for E batches; ids like E-003-00.
  * generate_from_prompt_ids(prompt_ids, dataset_split, completions_per_prompt, seed) for deterministic retrieval.
  * generate_from_custom_prompts(prompts, completions_per_prompt, seed) leveraging GSM8K templates but marking provenance as custom.
  * build_custom_sequence(prompt, response, metadata=None) for fully specified pairs; returns a singleton GeneratedBatch or SequenceRecord with teacher-forced stats.
  * Serialization helpers (save_batch, load_batch, clone_with_subset) to persist and reuse U batches when probing Fisher correlations repeatedly.
- Require updates to rlp_datasets/gsm8k_r1_template.py to annotate each sample's meta with a deterministic global_prompt_id; SampleGenerator must propagate this into SequenceRecord.
- Plan FisherKernelRunner refactor so it consumes GeneratedBatch instances directly, enabling U-U kernel queries (K(i, j) within U) and cumulative influence calculations sum_j K(t, t_j) * A(t_j) via stable sequence_id lookups.

Fisher Kernel Runner Refactor
-----------------------------
- Objectives:
  * Treat the update batch as a reusable workspace with cached gradients and Adam-preconditioned vectors.
  * Support ad-hoc Fisher-kernel queries between any sequence pair (U-U or U-vs-external) and influence accumulation \(\sum_j K(t,t_j) A_j\).
  * Delegate all batch construction to SampleGenerator so dataset provenance and metadata stay consistent.
- Plan revisions:
  * Redefine FisherKernelPlan to describe: (i) how to source the U workspace (generator kwargs or pre-saved path), (ii) which evaluation requests to execute (list of BatchRequest descriptors), and (iii) storage toggles (full K, top-k, serialization paths).
  * Introduce BatchRequest dataclass capturing the SampleGenerator entry point (kind \in {update, evaluation, prompt_ids, custom_prompts, custom_sequence, from_file}) plus parameters and optional sequence_id filters.
  * Create KernelWorkspace dataclass bundling: the GeneratedBatch for U, per-sequence gradient tensors (flattened or parameter-sharded), preconditioned gradients, Adam stats metadata, and lookup maps from sequence_id -> index.
  * Add GradientCache objects (one per sequence) that store: raw gradient view, preconditioned view, norm stats, and lazy materialization hooks so we can stream large models.
- Runner structure:
  * FisherKernelRunner.__init__ takes config + logger, instantiates SampleGenerator lazily.
  * prepare_update_workspace(plan) -> generates/loads the U batch (via SampleGenerator or file), computes gradients microbatch-wise, applies Adam diagonal preconditioning, and returns KernelWorkspace (optionally persisted to disk for reuse).
  * compute_self_kernel(workspace, sequence_ids=None, capture_full=False) -> forms K_UU or selected submatrix and stores diagnostics (cosine sims, norm ratios).
  * evaluate_batch(request, workspace, capture_full=None) -> materializes an E batch (SampleGenerator or provided) and streams gradient dot-products against workspace to produce:
    - Fisher kernel blocks (when requested).
    - Influence vector for each E sequence (delta_logpi using workspace advantages or overrides).
    - Top-k contributor summaries keyed by U sequence_id.
  * serialize_workspace / load_workspace helpers persist U batches + gradient caches (NPZ/torch.save) to avoid recomputation.
- Execution flow:
  1. Plan enumerates requests: e.g., build U workspace, optionally compute U-U kernel, evaluate prompt-id subset, check custom probes.
  2. Runner iterates through requests, reusing the workspace and SampleGenerator as needed.
  3. Results object aggregates per-request outputs plus metadata snapshots (config, SampleGenerator sampling metadata, gradient stats).
- Next implementation steps:
  * Define dataclasses (BatchRequest, KernelWorkspace, GradientCache, FisherKernelResults).
  * Refactor existing FisherKernelRunner scaffold to call SampleGenerator and operate on GeneratedBatch structures.
  * Implement gradient collection + Adam preconditioning utilities that accept GeneratedBatch and sequence filters.
  * Update CLI/plan ingestion to parse the new plan format and drive the refactored runner.

