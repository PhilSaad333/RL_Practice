{
  "experiment_type": "conservative_jackknife_B4096_train",
  "dataset": "gsm8k_r1_template",
  "split": "train",
  "B": 4096,
  "G": 8,
  "seed": null,
  "estimate_mean_per_seq_entropy": 2.4245440913109633,
  "variance_estimate": 0.000333374768468584,
  "std_dev_estimate": 0.01825855329615641,
  "distribution_analysis": {
    "count": 4096,
    "mean": 2.4245440913109633,
    "std": 1.16840475729896,
    "min": 0.6163040697574615,
    "q01": 0.8272020183503628,
    "q05": 1.0505626406520605,
    "q25": 1.558846578001976,
    "median": 2.2216068282723427,
    "q75": 3.013792783021927,
    "q90": 3.8121650964021683,
    "q95": 4.472801774740219,
    "q99": 6.690841650962839,
    "max": 9.201631546020508
  },
  "performance": {
    "total_duration_seconds": 3251.598082,
    "generation_duration_seconds": 3240.314747,
    "sequences_per_second": 10.11259786733304
  },
  "memory_management": {
    "approach": "conservative_batching",
    "gen_batch_size": 128,
    "tf_batch_size": 256,
    "reason": "avoid_oom_with_large_B"
  },
  "timestamp": "2025-08-29T05:54:56.849430"
}