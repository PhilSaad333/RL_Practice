{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d24fa2a",
   "metadata": {},
   "source": [
    "\n",
    "# Batch Size Comparison Diagnostics\n",
    "\n",
    "Compare DeltaH estimates for batches of size 256 versus synthetic 256-sample subsets drawn from E=2048 runs. Focus on the relative error `err_rel = 1 - (DeltaH_linear / DeltaH_true)` for selected eta values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cb5993",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "ROOT = Path('..')\n",
    "ROOT_2048 = ROOT / 'E_2048'\n",
    "ROOT_256 = ROOT / 'E_256'\n",
    "\n",
    "paths_2048 = sorted(ROOT_2048.glob('run_*/results.json'))\n",
    "paths_256 = sorted(ROOT_256.glob('run_*/results.json'))\n",
    "print(f\"Found {len(paths_2048)} E=2048 runs and {len(paths_256)} E=256 runs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e08d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_runs(paths):\n",
    "    runs = {}\n",
    "    for path in paths:\n",
    "        with path.open() as f:\n",
    "            runs[path.parent.name] = json.load(f)\n",
    "    return runs\n",
    "\n",
    "runs_2048 = load_runs(paths_2048)\n",
    "runs_256 = load_runs(paths_256)\n",
    "print(\"E=2048 run ids:\", list(runs_2048.keys()))\n",
    "print(\"E=256 run ids:\", list(runs_256.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba5aa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reference true totals from E=2048 runs for each eta\n",
    "reference_true_totals = {}\n",
    "for run_id, data in runs_2048.items():\n",
    "    for entry in data['true']['entries']:\n",
    "        eta = float(entry['eta'])\n",
    "        reference_true_totals.setdefault(eta, []).append(float(entry['delta_h_true']))\n",
    "reference_true_totals = {eta: float(np.mean(vals)) for eta, vals in reference_true_totals.items()}\n",
    "print('Reference true totals (E=2048):')\n",
    "for eta, val in reference_true_totals.items():\n",
    "    print(f\"  eta={eta:.2e}: delta_h_true={val:.6e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc41974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_eta_entry(data: dict, eta: float, *, tol: float = 1e-12) -> dict:\n",
    "    for entry in data['true']['entries']:\n",
    "        if abs(float(entry['eta']) - eta) <= max(tol, tol * abs(eta), 1e-6 * abs(eta)):\n",
    "            return entry\n",
    "    raise ValueError(f\"eta={eta} not found\")\n",
    "\n",
    "\n",
    "def per_sequence_contributions(data: dict, eta: float):\n",
    "    entry = select_eta_entry(data, eta)\n",
    "    diag = entry['diagnostics']\n",
    "\n",
    "    weights_sum = float(diag.get('weights_sum', 1.0))\n",
    "    norm_w = np.asarray(diag['normalized_weights'], dtype=float)\n",
    "    weights = norm_w * weights_sum\n",
    "    token_counts = np.asarray(diag['token_counts'], dtype=float)\n",
    "    h_new = np.asarray(diag['h_new'], dtype=float)\n",
    "    base_entropy = float(diag['base_entropy'])\n",
    "\n",
    "    denom = np.dot(token_counts, weights) if token_counts.size else 1.0\n",
    "    if denom == 0.0:\n",
    "        denom = 1.0\n",
    "    total_tokens = token_counts.sum() if token_counts.size else 1.0\n",
    "\n",
    "    true_seq = (weights * h_new) / denom - (token_counts / total_tokens) * base_entropy\n",
    "\n",
    "    approx_seq = data['approx']['per_sequence']\n",
    "    eta = float(eta)\n",
    "    linear_seq = np.asarray([rec['gdotv'] * eta for rec in approx_seq], dtype=float)\n",
    "    return true_seq, linear_seq\n",
    "\n",
    "\n",
    "def aggregate_err_rel(true_seq_subset: np.ndarray, linear_seq_subset: np.ndarray, true_total_full: float) -> float:\n",
    "    if true_total_full == 0:\n",
    "        return np.nan\n",
    "    linear_total_subset = linear_seq_subset.sum()\n",
    "    true_total_subset = true_seq_subset.sum()\n",
    "    return (linear_total_subset - true_total_subset) / true_total_full\n",
    "\n",
    "\n",
    "def aggregate_err_rel_from_run(data: dict, eta: float, true_total_full: float) -> float:\n",
    "    true_seq, linear_seq = per_sequence_contributions(data, eta)\n",
    "    return aggregate_err_rel(true_seq, linear_seq, true_total_full=true_total_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef32ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simulate_err_rel_from_2048(run_data: dict, eta: float, sample_size: int = 256, *, num_samples: int = 1000, seed: int = 0) -> np.ndarray:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    true_seq, linear_seq = per_sequence_contributions(run_data, eta)\n",
    "    n = true_seq.size\n",
    "    if n < sample_size:\n",
    "        raise ValueError(f\"Sample size {sample_size} exceeds available sequences {n}\")\n",
    "    true_total_full = true_seq.sum()\n",
    "\n",
    "    errs = []\n",
    "    for _ in range(num_samples):\n",
    "        idx = rng.choice(n, size=sample_size, replace=False)\n",
    "        errs.append(aggregate_err_rel(true_seq[idx], linear_seq[idx], true_total_full=true_total_full))\n",
    "    return np.asarray(errs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c31481",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collect_err_rel_across_runs(runs: dict, eta: float, true_total_ref: float) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for run_id, data in runs.items():\n",
    "        try:\n",
    "            true_seq, linear_seq = per_sequence_contributions(data, eta)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        err = aggregate_err_rel(true_seq, linear_seq, true_total_full=true_total_ref)\n",
    "        rows.append({'run': run_id, 'eta': eta, 'err_rel': err})\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e432de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compare_err_rel_distributions(eta: float, *, sample_size: int = 256, num_samples: int = 2000, seed: int = 0) -> None:\n",
    "    if eta not in reference_true_totals:\n",
    "        raise ValueError(f\"No reference DeltaH_true for eta={eta}\")\n",
    "    true_total_ref = reference_true_totals[eta]\n",
    "\n",
    "    actual_df = collect_err_rel_across_runs(runs_256, eta, true_total_ref=true_total_ref)\n",
    "    if actual_df.empty:\n",
    "        raise ValueError(f\"No E=256 runs found for eta={eta}\")\n",
    "\n",
    "    synthetic_errs = []\n",
    "    for run_id, data in runs_2048.items():\n",
    "        try:\n",
    "            errs = simulate_err_rel_from_2048(data, eta, sample_size=sample_size, num_samples=num_samples, seed=seed)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        synthetic_errs.append(errs)\n",
    "    if not synthetic_errs:\n",
    "        raise ValueError(f\"No E=2048 runs found for eta={eta}\")\n",
    "    synthetic_errs = np.concatenate(synthetic_errs)\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.hist(synthetic_errs, bins=60, alpha=0.7, label='Synthetic (from E=2048)', color='tab:blue')\n",
    "    for i, row in actual_df.iterrows():\n",
    "        plt.axvline(row['err_rel'], color='tab:orange', linestyle='--', linewidth=1.5,\n",
    "                    label='Actual E=256' if i == actual_df.index[0] else None)\n",
    "\n",
    "    plt.xlabel('err_rel = (DeltaH_linear - DeltaH_true_subset) / DeltaH_true_full')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'err_rel distribution comparison (eta={eta:.2e})')\n",
    "    plt.grid(True, ls=':', alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    summary = {\n",
    "        'eta': eta,\n",
    "        'synthetic_mean': float(np.nanmean(synthetic_errs)),\n",
    "        'synthetic_std': float(np.nanstd(synthetic_errs, ddof=1)),\n",
    "        'synthetic_min': float(np.nanmin(synthetic_errs)),\n",
    "        'synthetic_max': float(np.nanmax(synthetic_errs)),\n",
    "        'actual_values': actual_df['err_rel'].tolist(),\n",
    "    }\n",
    "    display(pd.DataFrame([summary]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac15d6cf",
   "metadata": {},
   "source": [
    "\n",
    "### Example Usage\n",
    "\n",
    "```python\n",
    "compare_err_rel_distributions(eta=1.6e-6, num_samples=2000)\n",
    "compare_err_rel_distributions(eta=3.2e-6, num_samples=2000)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2691ecfc",
   "metadata": {},
   "source": [
    "\n",
    "### Subsampling Error Distribution\n",
    "\n",
    "Sample random subsets (size `subset_size`) across all E=2048 runs, compute `err_rel = 1 - DeltaH_linear / DeltaH_true`, and examine the distribution along with mean/variance summaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_err_rel_across_runs(runs: dict, eta_values, *, subset_size: int = 256, samples_per_eta: int = 200, seed: int = 0) -> pd.DataFrame:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rows = []\n",
    "    for eta in eta_values:\n",
    "        for run_id, data in runs.items():\n",
    "            try:\n",
    "                true_seq, linear_seq = per_sequence_contributions(data, eta)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            n = true_seq.size\n",
    "            if n < subset_size:\n",
    "                continue\n",
    "            true_total_full = true_seq.sum()\n",
    "            for _ in range(samples_per_eta):\n",
    "                idx = rng.choice(n, size=subset_size, replace=False)\n",
    "                err = aggregate_err_rel(true_seq[idx], linear_seq[idx], true_total_full=true_total_full)\n",
    "                rows.append({'run': run_id, 'eta': eta, 'err_rel': err})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def summarize_err_rel_distribution(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for eta, group in df.groupby('eta'):\n",
    "        vals = group['err_rel'].dropna().to_numpy()\n",
    "        if vals.size == 0:\n",
    "            continue\n",
    "        rows.append({\n",
    "            'eta': eta,\n",
    "            'mean_err_rel': float(np.mean(vals)),\n",
    "            'std_err_rel': float(np.std(vals, ddof=1)),\n",
    "            'var_err_rel': float(np.var(vals, ddof=1)),\n",
    "            'min_err_rel': float(np.min(vals)),\n",
    "            'max_err_rel': float(np.max(vals)),\n",
    "            'num_samples': vals.size,\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def plot_err_rel_histograms(df: pd.DataFrame, eta_values) -> None:\n",
    "    num = len(eta_values)\n",
    "    fig, axes = plt.subplots(1, num, figsize=(5 * num, 4), sharey=True)\n",
    "    if num == 1:\n",
    "        axes = [axes]\n",
    "    for ax, eta in zip(axes, eta_values):\n",
    "        subset = df[df['eta'] == eta]['err_rel'].dropna()\n",
    "        ax.hist(subset, bins=60, color='tab:blue', alpha=0.75)\n",
    "        ax.set_title(f'eta={eta:.2e}')\n",
    "        ax.set_xlabel('err_rel = (DeltaH_linear_subset - DeltaH_true_subset) / DeltaH_true_full')\n",
    "        ax.grid(True, ls=':', alpha=0.5)\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc6447e",
   "metadata": {},
   "source": [
    "\n",
    "#### Example Usage\n",
    "\n",
    "```python\n",
    "eta_values = [1.6e-6, 3.2e-6]\n",
    "# Synthetic subsets from E=2048 runs\n",
    "subset_df = sample_err_rel_across_runs(runs_2048, eta_values, subset_size=256, samples_per_eta=500, seed=42)\n",
    "plot_err_rel_histograms(subset_df, eta_values)\n",
    "summarize_err_rel_distribution(subset_df)\n",
    "\n",
    "# Actual vs synthetic comparison at a single eta\n",
    "a_compare = compare_err_rel_distributions(eta=1.6e-6, num_samples=2000)\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
