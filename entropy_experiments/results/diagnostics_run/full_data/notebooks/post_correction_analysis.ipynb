{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40497230",
   "metadata": {},
   "source": [
    "\n",
    "# Post-Correction ΔH Analysis\n",
    "\n",
    "This notebook inspects runs produced after adding the SNIS denominator correction. It summarizes aggregate agreement between true and approximate ΔH values and visualizes per-sequence errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fe167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "RESULTS_ROOT_2048 = Path('..') / 'E_2048'\n",
    "RESULTS_ROOT_256 = Path('..') / 'E_256'\n",
    "result_paths_2048 = sorted(RESULTS_ROOT_2048.glob('run_*/results.json'))\n",
    "result_paths_256 = sorted(RESULTS_ROOT_256.glob('run_*/results.json'))\n",
    "print(f\"Found {len(result_paths_2048)} E=2048 run files and {len(result_paths_256)} E=256 run files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ee7447",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_run(path: Path):\n",
    "    with path.open() as f:\n",
    "        return json.load(f)\n",
    "\n",
    "runs_data_2048 = {path.parent.name: load_run(path) for path in result_paths_2048}\n",
    "runs_data_256 = {path.parent.name: load_run(path) for path in result_paths_256}\n",
    "print(\"E=2048 runs:\", list(runs_data_2048.keys()))\n",
    "print(\"E=256 runs:\", list(runs_data_256.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ac646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_rows = []\n",
    "for run_id, data in runs_data.items():\n",
    "    approx = data['approx']\n",
    "    gdotv_linear = float(approx['delta_h_per_lr'])\n",
    "    quad = approx.get('quadratic') or {}\n",
    "    gdotv_quad = float(quad.get('gdotv', gdotv_linear))\n",
    "    vHvv = quad.get('vHvv')\n",
    "\n",
    "    for entry in data['true']['entries']:\n",
    "        eta = float(entry['eta'])\n",
    "        delta_true = float(entry['delta_h_true'])\n",
    "        delta_linear = gdotv_linear * eta\n",
    "        delta_linquad = None\n",
    "        if vHvv is not None:\n",
    "            delta_linquad = gdotv_quad * eta + 0.5 * float(vHvv) * (eta ** 2)\n",
    "        summary_rows.append({\n",
    "            'run': run_id,\n",
    "            'eta': eta,\n",
    "            'delta_true': delta_true,\n",
    "            'delta_linear': delta_linear,\n",
    "            'delta_linquad': delta_linquad,\n",
    "            'linear_over_true': delta_linear / delta_true if delta_true != 0 else np.nan,\n",
    "            'linquad_over_true': (delta_linquad / delta_true) if (delta_true != 0 and delta_linquad is not None) else np.nan,\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values(['run', 'eta']).reset_index(drop=True)\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d0b7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Linear / True ratios:\")\n",
    "for _, row in summary_df.iterrows():\n",
    "    print(f\"{row['run']} η={row['eta']:.2e}: linear/true={row['linear_over_true']:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7306d844",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _select_eta_entry(data: dict, eta: float) -> dict:\n",
    "    for entry in data['true']['entries']:\n",
    "        if abs(float(entry['eta']) - eta) <= max(1e-12, 1e-6 * eta):\n",
    "            return entry\n",
    "    raise ValueError(f\"η={eta} not found in run\")\n",
    "\n",
    "\n",
    "def get_per_sequence_contributions(run_id: str, eta: float):\n",
    "    data = runs_data[run_id]\n",
    "    entry = _select_eta_entry(data, eta)\n",
    "    diag = entry['diagnostics']\n",
    "\n",
    "    weights_sum = float(diag['weights_sum']) if diag.get('weights_sum') is not None else 1.0\n",
    "    norm_w = np.asarray(diag['normalized_weights'], dtype=float)\n",
    "    weights = norm_w * weights_sum\n",
    "    token_counts = np.asarray(diag['token_counts'], dtype=float)\n",
    "    h_new = np.asarray(diag['h_new'], dtype=float)\n",
    "    base_entropy = float(diag['base_entropy'])\n",
    "\n",
    "    denom = np.dot(token_counts, weights) if token_counts.size else 1.0\n",
    "    if denom == 0.0:\n",
    "        denom = 1.0\n",
    "    total_tokens = token_counts.sum() if token_counts.size else 1.0\n",
    "\n",
    "    true_contrib = (weights * h_new) / denom - (token_counts / total_tokens) * base_entropy\n",
    "\n",
    "    approx_seq = data['approx']['per_sequence']\n",
    "    eta = float(eta)\n",
    "    linear_seq = np.asarray([rec['gdotv'] * eta for rec in approx_seq], dtype=float)\n",
    "\n",
    "    return true_contrib, linear_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500bf7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summarize_standard_errors() -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for run_id, data in runs_data.items():\n",
    "        approx_var = data['approx'].get('variance') or {}\n",
    "        quad_var = data['approx'].get('quadratic', {}).get('variance') or {}\n",
    "        for entry in data['true']['entries']:\n",
    "            eta = float(entry['eta'])\n",
    "            delta_true = float(entry['delta_h_true'])\n",
    "            delta_linear = float(data['approx']['delta_h_per_lr']) * eta\n",
    "            se_linear_raw = approx_var.get('se_shard')\n",
    "            se_linquad_raw = quad_var.get('se_gdotv')\n",
    "            rows.append({\n",
    "                'run': run_id,\n",
    "                'eta': eta,\n",
    "                'delta_true': delta_true,\n",
    "                'delta_linear': delta_linear,\n",
    "                'se_linear_raw': se_linear_raw,\n",
    "                'se_linear': (se_linear_raw * eta) if se_linear_raw is not None else None,\n",
    "                'se_linear_jackknife': (approx_var.get('se_jackknife') * eta) if approx_var.get('se_jackknife') is not None else None,\n",
    "                'se_gdotv_raw': se_linquad_raw,\n",
    "                'se_gdotv': (se_linquad_raw * eta) if se_linquad_raw is not None else None,\n",
    "                'se_vHvv': quad_var.get('se_vHvv'),\n",
    "                'ess_true': entry['diagnostics'].get('ess'),\n",
    "                'num_shards': approx_var.get('num_shards'),\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "se_df = summarize_standard_errors()\n",
    "se_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df9195",
   "metadata": {},
   "source": [
    "\n",
    "### Per-Sequence Error Histogram\n",
    "\n",
    "The helper below plots `|ΔH_true_i - ΔH_linear_i| / |ΔH_true|` for a chosen run and learning rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de47d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_normalized_abs_error(run_id: str, eta: float, bins: int = 60) -> None:\n",
    "    true_seq, linear_seq = get_per_sequence_contributions(run_id, eta)\n",
    "    entry = _select_eta_entry(runs_data[run_id], eta)\n",
    "    delta_true = float(entry['delta_h_true'])\n",
    "    norm = abs(delta_true) if delta_true != 0 else 1.0\n",
    "\n",
    "    norm_abs_error = np.abs(true_seq - linear_seq) / norm\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(norm_abs_error, bins=bins, color='tab:blue', alpha=0.8)\n",
    "    plt.xlabel(\"|ΔH_true_i - ΔH_linear_i| / |ΔH_true|\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"Normalized per-sequence error{run_id}, η={eta:.2e}\")\n",
    "    plt.grid(True, ls=':', alpha=0.5)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7606c58",
   "metadata": {},
   "source": [
    "\n",
    "#### Example Usage\n",
    "\n",
    "```python\n",
    "plot_normalized_abs_error('run_01', 8e-06)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40333b2",
   "metadata": {},
   "source": [
    "\n",
    "### Agreement Within Error Bars\n",
    "\n",
    "The table below computes standard errors for both true and linear estimates (using per-sequence variability for the true value) and checks whether the two agree within one combined standard deviation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cae55bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_true_se(run_id: str, eta: float) -> float:\n",
    "    true_seq, _ = get_per_sequence_contributions(run_id, eta)\n",
    "    if true_seq.size == 0:\n",
    "        return 0.0\n",
    "    return float(np.std(true_seq, ddof=1) / np.sqrt(true_seq.size))\n",
    "\n",
    "\n",
    "def build_agreement_table() -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for run_id, data in runs_data.items():\n",
    "        approx_var = data['approx'].get('variance') or {}\n",
    "        for entry in data['true']['entries']:\n",
    "            eta = float(entry['eta'])\n",
    "            delta_true = float(entry['delta_h_true'])\n",
    "            delta_linear = float(data['approx']['delta_h_per_lr']) * eta\n",
    "            se_linear = (approx_var.get('se_shard') or 0.0) * eta\n",
    "            se_true = compute_true_se(run_id, eta)\n",
    "            diff = delta_linear - delta_true\n",
    "            combined = (se_linear ** 2 + se_true ** 2) ** 0.5\n",
    "            within = abs(diff) <= combined if combined > 0 else np.nan\n",
    "            rows.append({\n",
    "                'run': run_id,\n",
    "                'eta': eta,\n",
    "                'delta_true': delta_true,\n",
    "                'delta_linear': delta_linear,\n",
    "                'se_true': se_true,\n",
    "                'se_linear': se_linear,\n",
    "                'diff': diff,\n",
    "                'combined_se': combined,\n",
    "                'within_1sigma': within,\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "agreement_df = build_agreement_table()\n",
    "agreement_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00e5928",
   "metadata": {},
   "source": [
    "\n",
    "### Per-Sequence Contribution Histograms\n",
    "\n",
    "Visualize the distribution of contributions for the true estimate, the linear approximation, and the lin+quad approximation (if curvature diagnostics were captured).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e45dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_contribution_histograms(run_id: str, eta: float, bins: int = 60) -> None:\n",
    "    data = runs_data[run_id]\n",
    "    entry = _select_eta_entry(data, eta)\n",
    "    diag = entry['diagnostics']\n",
    "\n",
    "    weights_sum = float(diag['weights_sum']) if diag.get('weights_sum') is not None else 1.0\n",
    "    norm_w = np.asarray(diag['normalized_weights'], dtype=float)\n",
    "    weights = norm_w * weights_sum\n",
    "    token_counts = np.asarray(diag['token_counts'], dtype=float)\n",
    "    h_new = np.asarray(diag['h_new'], dtype=float)\n",
    "    base_entropy = float(diag['base_entropy'])\n",
    "\n",
    "    denom = np.dot(token_counts, weights) if token_counts.size else 1.0\n",
    "    if denom == 0.0:\n",
    "        denom = 1.0\n",
    "    total_tokens = token_counts.sum() if token_counts.size else 1.0\n",
    "\n",
    "    true_contrib = (weights * h_new) / denom - (token_counts / total_tokens) * base_entropy\n",
    "\n",
    "    approx_seq = data['approx']['per_sequence']\n",
    "    eta = float(eta)\n",
    "    linear_seq = np.asarray([rec['gdotv'] * eta for rec in approx_seq], dtype=float)\n",
    "\n",
    "    linquad_seq = None\n",
    "    if data['approx'].get('quadratic') and 'per_sequence_vhvv' in data['approx']['quadratic']:\n",
    "        vhvv = np.asarray(data['approx']['quadratic']['per_sequence_vhvv'], dtype=float)\n",
    "        linquad_seq = linear_seq + 0.5 * (eta ** 2) * vhvv\n",
    "\n",
    "    datasets = [(\"ΔH true contrib\", true_contrib), (\"ΔH linear\", linear_seq)]\n",
    "    if linquad_seq is not None:\n",
    "        datasets.append((\"ΔH lin+quad\", linquad_seq))\n",
    "\n",
    "    num = len(datasets)\n",
    "    fig, axes = plt.subplots(1, num, figsize=(5 * num, 4), sharey=True)\n",
    "    if num == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, (label, values) in zip(axes, datasets):\n",
    "        ax.hist(values, bins=bins, color='tab:blue', alpha=0.8)\n",
    "        ax.axvline(0.0, color='black', linestyle='--', linewidth=1)\n",
    "        ax.set_title(f\"{label} (η={eta:.2e})\")\n",
    "        ax.set_xlabel(\"Contribution per sequence\")\n",
    "        ax.grid(True, ls=':', alpha=0.5)\n",
    "        max_abs = np.max(np.abs(values))\n",
    "        if max_abs == 0:\n",
    "            max_abs = 1e-12\n",
    "        padding = 0.05 * max_abs\n",
    "        ax.set_xlim(-max_abs - padding, max_abs + padding)\n",
    "\n",
    "    axes[0].set_ylabel(\"Count\")\n",
    "    plt.suptitle(f\"Per-sequence contributions for {run_id}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e74427",
   "metadata": {},
   "source": [
    "\n",
    "### Truncation and Clipping Experiments\n",
    "\n",
    "The helpers below explore how removing or clipping the largest-magnitude approximate contributions affects agreement between the true and approximate ΔH estimates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c6557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summarize_truncation(run_id: str, eta: float, keep_quantile: float = 0.99) -> dict:\n",
    "    true_seq, linear_seq = get_per_sequence_contributions(run_id, eta)\n",
    "    linquad_seq = None\n",
    "    data = runs_data[run_id]\n",
    "    if data['approx'].get('quadratic') and 'per_sequence_vhvv' in data['approx']['quadratic']:\n",
    "        vhvv = np.asarray(data['approx']['quadratic']['per_sequence_vhvv'], dtype=float)\n",
    "        linquad_seq = linear_seq + 0.5 * (eta ** 2) * vhvv\n",
    "\n",
    "    threshold = np.quantile(np.abs(linear_seq), keep_quantile)\n",
    "    mask = np.abs(linear_seq) <= threshold\n",
    "    kept_pct = mask.mean() * 100\n",
    "\n",
    "    summary = {\n",
    "        'run': run_id,\n",
    "        'eta': eta,\n",
    "        'keep_quantile': keep_quantile,\n",
    "        'threshold': threshold,\n",
    "        'kept_percent': kept_pct,\n",
    "        'delta_true_trunc': float(true_seq[mask].sum()),\n",
    "        'delta_linear_trunc': float(linear_seq[mask].sum()),\n",
    "    }\n",
    "    if linquad_seq is not None:\n",
    "        summary['delta_linquad_trunc'] = float(linquad_seq[mask].sum())\n",
    "    return summary\n",
    "\n",
    "\n",
    "def summarize_clipping(run_id: str, eta: float, clip_value: float) -> dict:\n",
    "    true_seq, linear_seq = get_per_sequence_contributions(run_id, eta)\n",
    "    linquad_seq = None\n",
    "    data = runs_data[run_id]\n",
    "    if data['approx'].get('quadratic') and 'per_sequence_vhvv' in data['approx']['quadratic']:\n",
    "        vhvv = np.asarray(data['approx']['quadratic']['per_sequence_vhvv'], dtype=float)\n",
    "        linquad_seq = linear_seq + 0.5 * (eta ** 2) * vhvv\n",
    "\n",
    "    clipped_linear = np.clip(linear_seq, -clip_value, clip_value)\n",
    "    summary = {\n",
    "        'run': run_id,\n",
    "        'eta': eta,\n",
    "        'clip_value': clip_value,\n",
    "        'delta_true_clip': float(np.clip(true_seq, -clip_value, clip_value).sum()),\n",
    "        'delta_linear_clip': float(clipped_linear.sum()),\n",
    "    }\n",
    "    if linquad_seq is not None:\n",
    "        clipped_linquad = np.clip(linquad_seq, -clip_value, clip_value)\n",
    "        summary['delta_linquad_clip'] = float(clipped_linquad.sum())\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4806ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "# trunc_result = summarize_truncation('run_01', 8e-06, keep_quantile=0.95)\n",
    "# clip_result = summarize_clipping('run_01', 8e-06, clip_value=5e-4)\n",
    "# trunc_result, clip_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b139bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def batch_truncation_summary(keep_quantiles=(0.99, 0.95, 0.90)) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for run_id, data in runs_data.items():\n",
    "        for entry in data['true']['entries']:\n",
    "            eta = float(entry['eta'])\n",
    "            true_seq, linear_seq = get_per_sequence_contributions(run_id, eta)\n",
    "            vhvv = None\n",
    "            if data['approx'].get('quadratic') and 'per_sequence_vhvv' in data['approx']['quadratic']:\n",
    "                vhvv = np.asarray(data['approx']['quadratic']['per_sequence_vhvv'], dtype=float)\n",
    "            for q in keep_quantiles:\n",
    "                thr = np.quantile(np.abs(linear_seq), q)\n",
    "                mask = np.abs(linear_seq) <= thr\n",
    "                row = {\n",
    "                    'run': run_id,\n",
    "                    'eta': eta,\n",
    "                    'keep_quantile': q,\n",
    "                    'threshold': thr,\n",
    "                    'kept_percent': mask.mean() * 100,\n",
    "                    'delta_true_trunc': float(true_seq[mask].sum()),\n",
    "                    'delta_linear_trunc': float(linear_seq[mask].sum()),\n",
    "                }\n",
    "                if vhvv is not None:\n",
    "                    linquad_seq = linear_seq + 0.5 * (eta ** 2) * vhvv\n",
    "                    row['delta_linquad_trunc'] = float(linquad_seq[mask].sum())\n",
    "                rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "trunc_df = batch_truncation_summary()\n",
    "trunc_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e66afc",
   "metadata": {},
   "source": [
    "\n",
    "### Clip Sweep Visualization\n",
    "\n",
    "The helper below sweeps clipping thresholds (using quantiles of |ΔH linear|) and shows how the clipped totals compare between the true, linear, and lin+quad estimates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3e9f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_clip_sweep(run_id: str, eta: float, base_quantile: float = 0.999, steps: int = 10) -> None:\n",
    "    true_seq, linear_seq = get_per_sequence_contributions(run_id, eta)\n",
    "    linquad_seq = None\n",
    "    data = runs_data[run_id]\n",
    "    if data['approx'].get('quadratic') and 'per_sequence_vhvv' in data['approx']['quadratic']:\n",
    "        vhvv = np.asarray(data['approx']['quadratic']['per_sequence_vhvv'], dtype=float)\n",
    "        linquad_seq = linear_seq + 0.5 * (eta ** 2) * vhvv\n",
    "\n",
    "    quantiles = [base_quantile ** k for k in range(steps, -1, -1)]\n",
    "    thresholds = [np.quantile(np.abs(linear_seq), q) for q in quantiles]\n",
    "\n",
    "    clipped_true = []\n",
    "    clipped_linear = []\n",
    "    clipped_linquad = []\n",
    "\n",
    "    for thr in thresholds:\n",
    "        clipped_true.append(float(np.clip(true_seq, -thr, thr).sum()))\n",
    "        clipped_linear.append(float(np.clip(linear_seq, -thr, thr).sum()))\n",
    "        if linquad_seq is not None:\n",
    "            clipped_linquad.append(float(np.clip(linquad_seq, -thr, thr).sum()))\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.plot(thresholds, clipped_true, label='ΔH true (clipped)', marker='o')\n",
    "    plt.plot(thresholds, clipped_linear, label='ΔH linear (clipped)', marker='s')\n",
    "    if clipped_linquad:\n",
    "        plt.plot(thresholds, clipped_linquad, label='ΔH lin+quad (clipped)', marker='^')\n",
    "\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Clipping threshold (|ΔH contribution|)')\n",
    "    plt.ylabel('Clipped sum')\n",
    "    plt.title(f'Clip sweep for {run_id}, η={eta:.2e}')\n",
    "    plt.grid(True, which='both', ls=':', alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392e2adf",
   "metadata": {},
   "source": [
    "\n",
    "### Reweighted Estimates by Filtering Strategy\n",
    "\n",
    "Compare raw ΔH estimates with versions produced by truncating or clipping the largest |ΔH linear| contributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7871fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compare_filtered_estimates(run_id: str, eta: float, keep_quantiles=(0.99, 0.95), clip_thresholds=(5e-4, 1e-4)) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    data = runs_data[run_id]\n",
    "    entry = _select_eta_entry(data, eta)\n",
    "    delta_true = float(entry['delta_h_true'])\n",
    "    delta_linear = float(data['approx']['delta_h_per_lr']) * eta\n",
    "    vhvv = None\n",
    "    if data['approx'].get('quadratic') and 'per_sequence_vhvv' in data['approx']['quadratic']:\n",
    "        vhvv = np.asarray(data['approx']['quadratic']['per_sequence_vhvv'], dtype=float)\n",
    "        delta_linquad = delta_linear + 0.5 * float(data['approx']['quadratic']['vHvv']) * (eta ** 2)\n",
    "    else:\n",
    "        delta_linquad = None\n",
    "\n",
    "    rows.append({'strategy': 'raw', 'delta_true': delta_true, 'delta_linear': delta_linear, 'delta_linquad': delta_linquad})\n",
    "\n",
    "    for q in keep_quantiles:\n",
    "        trunc = summarize_truncation(run_id, eta, keep_quantile=q)\n",
    "        rows.append({'strategy': f'truncate@{q}', 'delta_true': trunc['delta_true_trunc'], 'delta_linear': trunc['delta_linear_trunc'], 'delta_linquad': trunc.get('delta_linquad_trunc')})\n",
    "\n",
    "    for clip in clip_thresholds:\n",
    "        clipped = summarize_clipping(run_id, eta, clip)\n",
    "        rows.append({'strategy': f'clip@{clip}', 'delta_true': clipped['delta_true_clip'], 'delta_linear': clipped['delta_linear_clip'], 'delta_linquad': clipped.get('delta_linquad_clip')})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Example usage:\n",
    "# compare_filtered_estimates('run_01', 8e-06)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855cfc5c",
   "metadata": {},
   "source": [
    "\n",
    "### Truncation Sweep Plot\n",
    "\n",
    "Plot the ratio of truncated ΔH estimates (linear and lin+quad) relative to the true truncated value across a sweep of keep-quantiles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433b6eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_truncation_ratio(run_id: str, eta: float, keep_quantiles=None) -> None:\n",
    "    if keep_quantiles is None:\n",
    "        keep_quantiles = [1.0] + [0.999 ** k for k in range(10, -1, -1)]\n",
    "\n",
    "    summaries = []\n",
    "    for q in keep_quantiles:\n",
    "        summary = summarize_truncation(run_id, eta, keep_quantile=q)\n",
    "        summaries.append(summary)\n",
    "\n",
    "    df = pd.DataFrame(summaries)\n",
    "    delta_true = df['delta_true_trunc'].to_numpy()\n",
    "    ratios_linear = df['delta_linear_trunc'] / delta_true\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.plot(df['keep_quantile'], ratios_linear, marker='o', label='linear / true')\n",
    "\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('keep_quantile (log scale)')\n",
    "    plt.ylabel('ratio to true')\n",
    "    plt.title(f'Truncation sweep for {run_id}, η={eta:.2e}')\n",
    "    plt.grid(True, which='both', ls=':', alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
