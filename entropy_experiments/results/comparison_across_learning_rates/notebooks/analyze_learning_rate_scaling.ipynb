{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Learning Rate Scaling in Entropy Experiments\n",
    "\n",
    "This notebook analyzes how deltaH_true scales with learning rate across multiple experimental runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Set up matplotlib\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load all run results\nresults_dir = Path('..')  # Changed to parent directory since we're now in notebooks/\nruns_data = {}\n\nfor run_id in range(1, 9):\n    run_dir = results_dir / f'run_{run_id:02d}'\n    results_file = run_dir / 'results.json'\n    \n    if results_file.exists():\n        with open(results_file, 'r') as f:\n            runs_data[f'run_{run_id:02d}'] = json.load(f)\n        print(f\"Loaded run_{run_id:02d}\")\n    else:\n        print(f\"Warning: run_{run_id:02d} not found\")\n\nprint(f\"\\nTotal runs loaded: {len(runs_data)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract eta values and deltaH_true for all runs\n",
    "all_results = {}\n",
    "\n",
    "for run_name, data in runs_data.items():\n",
    "    sweep = data['sweep']\n",
    "    etas = [item['eta'] for item in sweep]\n",
    "    deltaH_true = [abs(item['deltaH_true']) for item in sweep]  # Taking absolute value\n",
    "    \n",
    "    all_results[run_name] = {\n",
    "        'etas': np.array(etas),\n",
    "        'deltaH_true': np.array(deltaH_true)\n",
    "    }\n",
    "\n",
    "# Check the eta values (should be powers of 2)\n",
    "sample_run = list(all_results.values())[0]\n",
    "print(\"Learning rates (eta):\")\n",
    "for i, eta in enumerate(sample_run['etas']):\n",
    "    if i > 0:\n",
    "        ratio = eta / sample_run['etas'][i-1]\n",
    "        print(f\"  {eta:.2e} (ratio to previous: {ratio:.1f})\")\n",
    "    else:\n",
    "        print(f\"  {eta:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ratios of deltaH_true between consecutive etas\n",
    "doubling_ratios = {}\n",
    "\n",
    "for run_name, data in all_results.items():\n",
    "    deltaH = data['deltaH_true']\n",
    "    ratios = []\n",
    "    \n",
    "    for i in range(1, len(deltaH)):\n",
    "        if deltaH[i-1] > 0:  # Avoid division by zero\n",
    "            ratio = deltaH[i] / deltaH[i-1]\n",
    "            ratios.append(ratio)\n",
    "    \n",
    "    doubling_ratios[run_name] = ratios\n",
    "\n",
    "# Create DataFrame for easier visualization\n",
    "df_ratios = pd.DataFrame(doubling_ratios).T\n",
    "df_ratios.columns = [f'η_{i+1}/η_{i}' for i in range(len(df_ratios.columns))]\n",
    "\n",
    "print(\"Ratios of deltaH_true between consecutive learning rates:\")\n",
    "print(\"(Should be ~2 if deltaH_true scales linearly with η)\\n\")\n",
    "print(df_ratios.round(2))\n",
    "print(\"\\nMean ratios across runs:\")\n",
    "print(df_ratios.mean().round(2))\n",
    "print(\"\\nStd of ratios across runs:\")\n",
    "print(df_ratios.std().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Bar chart showing deviation from perfect doubling\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Calculate deviation from 2.0 for each ratio\n",
    "deviations = df_ratios - 2.0\n",
    "\n",
    "# Plot bars for each run\n",
    "x = np.arange(len(df_ratios.columns))\n",
    "width = 0.1\n",
    "\n",
    "for i, (run_name, values) in enumerate(deviations.iterrows()):\n",
    "    offset = (i - len(deviations)/2) * width\n",
    "    ax.bar(x + offset, values, width, label=run_name, alpha=0.8)\n",
    "\n",
    "ax.axhline(y=0, color='black', linestyle='--', alpha=0.5, label='Perfect doubling (ratio=2)')\n",
    "ax.set_xlabel('Consecutive η pairs')\n",
    "ax.set_ylabel('Deviation from perfect doubling (ratio - 2.0)')\n",
    "ax.set_title('How close is deltaH_true to doubling with each doubling of η?')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(df_ratios.columns)\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Line plot showing deltaH_true vs eta for all runs\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Left plot: log-log scale\n",
    "for run_name, data in all_results.items():\n",
    "    ax1.loglog(data['etas'], data['deltaH_true'], 'o-', label=run_name, alpha=0.7, markersize=6)\n",
    "\n",
    "# Add reference line with slope 1 (perfect linear scaling)\n",
    "etas_ref = sample_run['etas']\n",
    "deltaH_ref = sample_run['deltaH_true'][0] * (etas_ref / etas_ref[0])\n",
    "ax1.loglog(etas_ref, deltaH_ref, 'k--', alpha=0.5, label='Perfect linear scaling', linewidth=2)\n",
    "\n",
    "ax1.set_xlabel('Learning rate (η)')\n",
    "ax1.set_ylabel('|deltaH_true|')\n",
    "ax1.set_title('deltaH_true vs Learning Rate (log-log scale)')\n",
    "ax1.legend(fontsize=9)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Right plot: Normalized deltaH/eta ratio\n",
    "for run_name, data in all_results.items():\n",
    "    ratio = data['deltaH_true'] / data['etas']\n",
    "    ax2.semilogx(data['etas'], ratio / ratio[0], 'o-', label=run_name, alpha=0.7, markersize=6)\n",
    "\n",
    "ax2.axhline(y=1, color='black', linestyle='--', alpha=0.5, label='Perfect linear scaling')\n",
    "ax2.set_xlabel('Learning rate (η)')\n",
    "ax2.set_ylabel('(deltaH/η) normalized to first point')\n",
    "ax2.set_title('Normalized deltaH/η Ratio vs Learning Rate')\n",
    "ax2.legend(fontsize=9)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3: Box plot of doubling ratios\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Prepare data for box plot\n",
    "box_data = [df_ratios[col].values for col in df_ratios.columns]\n",
    "\n",
    "bp = ax.boxplot(box_data, labels=df_ratios.columns, patch_artist=True)\n",
    "\n",
    "# Color the boxes\n",
    "for patch in bp['boxes']:\n",
    "    patch.set_facecolor('lightblue')\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "# Add a horizontal line at y=2\n",
    "ax.axhline(y=2, color='red', linestyle='--', alpha=0.7, label='Expected ratio (2.0) for linear scaling')\n",
    "\n",
    "# Add individual points\n",
    "for i, col in enumerate(df_ratios.columns):\n",
    "    y = df_ratios[col].values\n",
    "    x = np.random.normal(i+1, 0.04, size=len(y))\n",
    "    ax.scatter(x, y, alpha=0.6, s=30, color='darkblue')\n",
    "\n",
    "ax.set_xlabel('Consecutive η pairs')\n",
    "ax.set_ylabel('Ratio of deltaH_true values')\n",
    "ax.set_title('Distribution of deltaH Doubling Ratios Across Runs')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"Summary Statistics for Doubling Ratios\\n\" + \"=\"*40)\n",
    "print(\"\\nExpected ratio for perfect linear scaling: 2.00\\n\")\n",
    "\n",
    "for col in df_ratios.columns:\n",
    "    values = df_ratios[col]\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Mean:   {values.mean():.3f}\")\n",
    "    print(f\"  Median: {values.median():.3f}\")\n",
    "    print(f\"  Std:    {values.std():.3f}\")\n",
    "    print(f\"  Min:    {values.min():.3f}\")\n",
    "    print(f\"  Max:    {values.max():.3f}\")\n",
    "    print(f\"  % deviation from 2.0: {abs(values.mean() - 2.0) / 2.0 * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze where the linear approximation breaks down\n",
    "print(\"Analysis of Linear Scaling Breakdown\\n\" + \"=\"*40)\n",
    "\n",
    "threshold_deviation = 0.2  # 20% deviation from expected ratio of 2\n",
    "\n",
    "for run_name in all_results.keys():\n",
    "    ratios = doubling_ratios[run_name]\n",
    "    etas = all_results[run_name]['etas']\n",
    "    \n",
    "    print(f\"\\n{run_name}:\")\n",
    "    for i, ratio in enumerate(ratios):\n",
    "        deviation = abs(ratio - 2.0) / 2.0\n",
    "        if deviation > threshold_deviation:\n",
    "            print(f\"  Significant deviation at η_{i+1}={etas[i+1]:.2e}: ratio={ratio:.2f} ({deviation*100:.1f}% off)\")\n",
    "    \n",
    "    # Find where it starts deviating consistently\n",
    "    for i in range(len(ratios)):\n",
    "        if all(abs(r - 2.0) / 2.0 > threshold_deviation for r in ratios[i:]):\n",
    "            print(f\"  Linear scaling breaks down starting at η={etas[i+1]:.2e}\")\n",
    "            break\n",
    "    else:\n",
    "        if any(abs(r - 2.0) / 2.0 > threshold_deviation for r in ratios[-2:]):\n",
    "            print(f\"  Linear scaling degrades at higher learning rates\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Linear fitting analysis - excluding η_0 and η_6, η_7 where numerical errors or quadratic effects dominate\nfrom scipy import stats\nimport numpy as np\n\nprint(\"Linear Fitting Analysis (Excluding Problematic Regions)\\n\" + \"=\"*60)\nprint(\"Excluding: η_0 (numerical precision errors) and η_6, η_7 (quadratic effects)\")\nprint()\n\n# Store fitted parameters for each run\nfit_results = []\n\nfig, axes = plt.subplots(2, 4, figsize=(16, 8))\naxes = axes.flatten()\n\nfor idx, (run_name, data) in enumerate(all_results.items()):\n    etas = data['etas']\n    deltaH = data['deltaH_true']\n    \n    # Select indices 1-5 (excluding 0, 6, 7)\n    # This corresponds to η_1 through η_5\n    valid_indices = slice(1, 6)\n    etas_fit = etas[valid_indices]\n    deltaH_fit = deltaH[valid_indices]\n    \n    # Perform linear regression using scipy.stats\n    res = stats.linregress(etas_fit, deltaH_fit)\n    \n    slope = res.slope\n    intercept = res.intercept\n    r2 = res.rvalue**2  # R-squared is the square of correlation coefficient\n    \n    fit_results.append({\n        'run': run_name,\n        'slope': slope,\n        'intercept': intercept,\n        'r2': r2,\n        'stderr': res.stderr,\n        'pvalue': res.pvalue\n    })\n    \n    # Plot\n    ax = axes[idx]\n    \n    # Plot all points\n    ax.scatter(etas, deltaH, alpha=0.5, color='gray', label='All data', s=30)\n    \n    # Highlight fitted points\n    ax.scatter(etas_fit, deltaH_fit, color='blue', label='Fitted points', s=50)\n    \n    # Plot fitted line extended to η=0\n    eta_range = np.linspace(0, etas[-1], 100)\n    deltaH_pred = slope * eta_range + intercept\n    ax.plot(eta_range, deltaH_pred, 'r-', alpha=0.7, label=f'Fit: y = {slope:.1f}η + {intercept:.2e}')\n    \n    # Mark the y-intercept\n    ax.scatter(0, intercept, color='green', s=100, marker='*', zorder=5, \n               label=f'Y-intercept: {intercept:.2e}')\n    \n    ax.set_xlabel('Learning rate (η)')\n    ax.set_ylabel('|deltaH_true|')\n    ax.set_title(f'{run_name}: R² = {r2:.4f}')\n    ax.grid(True, alpha=0.3)\n    ax.legend(fontsize=7, loc='upper left')\n    \n    # Set x-axis to start from 0\n    ax.set_xlim(left=-etas[-1]*0.02, right=etas[-1]*1.1)\n\nplt.suptitle('Linear Fits to deltaH_true vs η (Using η₁ through η₅)', fontsize=14, y=1.02)\nplt.tight_layout()\nplt.show()\n\n# Summary table\ndf_fits = pd.DataFrame(fit_results)\nprint(\"\\nFitted Parameters Summary:\")\nprint(df_fits.to_string(index=False))\n\nprint(\"\\n\" + \"-\"*60)\nprint(\"Statistical Summary Across Runs:\")\nprint(f\"Mean intercept:   {df_fits['intercept'].mean():.3e} ± {df_fits['intercept'].std():.3e}\")\nprint(f\"Mean slope:       {df_fits['slope'].mean():.1f} ± {df_fits['slope'].std():.1f}\")\nprint(f\"Mean R²:          {df_fits['r2'].mean():.4f} ± {df_fits['r2'].std():.4f}\")\n\n# Check how close intercepts are to zero\nprint(\"\\n\" + \"-\"*60)\nprint(\"Analysis of Y-Intercepts (Should be ≈0 for perfect linear scaling):\")\nintercepts = df_fits['intercept'].values\nprint(f\"  Mean absolute intercept: {np.mean(np.abs(intercepts)):.3e}\")\nprint(f\"  Max absolute intercept:  {np.max(np.abs(intercepts)):.3e}\")\nprint(f\"  Intercept as % of typical deltaH at η=1e-6: {np.mean(np.abs(intercepts))/(1e-6 * df_fits['slope'].mean()) * 100:.1f}%\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}