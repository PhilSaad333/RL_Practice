{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of deltaH Approximations vs True Values\n",
    "\n",
    "This notebook analyzes the accuracy of linear and linear+quadratic approximations to deltaH_true,\n",
    "excluding η₀ (due to numerical precision issues) but including large η values to test quadratic corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up matplotlib\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all run results\n",
    "results_dir = Path('..')  # Parent directory since we're in notebooks/\n",
    "runs_data = {}\n",
    "\n",
    "for run_id in range(1, 9):\n",
    "    run_dir = results_dir / f'run_{run_id:02d}'\n",
    "    results_file = run_dir / 'results.json'\n",
    "    \n",
    "    if results_file.exists():\n",
    "        with open(results_file, 'r') as f:\n",
    "            runs_data[f'run_{run_id:02d}'] = json.load(f)\n",
    "        print(f\"Loaded run_{run_id:02d}\")\n",
    "\n",
    "print(f\"\\nTotal runs loaded: {len(runs_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and organize data, excluding η₀\n",
    "all_data = []\n",
    "\n",
    "for run_name, data in runs_data.items():\n",
    "    sweep = data['sweep'][1:]  # Skip η₀\n",
    "    curvature = data.get('curvature', {})\n",
    "    \n",
    "    for item in sweep:\n",
    "        eta = item['eta']\n",
    "        record = {\n",
    "            'run': run_name,\n",
    "            'eta': eta,\n",
    "            'deltaH_true': abs(item['deltaH_true']),\n",
    "            'deltaH_linear': abs(item['deltaH_approx_linear']),\n",
    "            'deltaH_linquad': abs(item['deltaH_approx_linquad']),\n",
    "            'eta_star': curvature.get('eta_star', np.nan),\n",
    "            'gdotv': abs(curvature.get('gdotv', np.nan)),\n",
    "            'vHvv': curvature.get('vHvv', np.nan)\n",
    "        }\n",
    "        \n",
    "        # Calculate errors\n",
    "        record['error_linear'] = record['deltaH_linear'] - record['deltaH_true']\n",
    "        record['error_linquad'] = record['deltaH_linquad'] - record['deltaH_true']\n",
    "        record['rel_error_linear'] = record['error_linear'] / record['deltaH_true'] if record['deltaH_true'] > 0 else np.nan\n",
    "        record['rel_error_linquad'] = record['error_linquad'] / record['deltaH_true'] if record['deltaH_true'] > 0 else np.nan\n",
    "        \n",
    "        all_data.append(record)\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "print(f\"Total data points: {len(df)}\")\n",
    "print(f\"Unique η values: {sorted(df['eta'].unique())}\")\n",
    "print(f\"\\nData shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Overview Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Analysis of approximation ratios (deltaH_approx/deltaH_true)\n# This ratio has the learning rate scaled out, allowing direct comparison across all η values\n\n# Calculate ratios\ndf['ratio_linear'] = df['deltaH_linear'] / df['deltaH_true']\ndf['ratio_linquad'] = df['deltaH_linquad'] / df['deltaH_true']\n\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n# Histogram of linear approximation ratio\naxes[0,0].hist(df['ratio_linear'], bins=50, alpha=0.7, color='blue', edgecolor='black')\naxes[0,0].axvline(x=1, color='red', linestyle='--', linewidth=2, label='Perfect approximation (ratio=1)')\naxes[0,0].set_xlabel('deltaH_linear / deltaH_true')\naxes[0,0].set_ylabel('Frequency')\naxes[0,0].set_title('Linear Approximation Ratio Distribution')\naxes[0,0].legend()\naxes[0,0].grid(True, alpha=0.3)\n\n# Histogram of linquad approximation ratio\naxes[0,1].hist(df['ratio_linquad'], bins=50, alpha=0.7, color='green', edgecolor='black')\naxes[0,1].axvline(x=1, color='red', linestyle='--', linewidth=2, label='Perfect approximation (ratio=1)')\naxes[0,1].set_xlabel('deltaH_linquad / deltaH_true')\naxes[0,1].set_ylabel('Frequency')\naxes[0,1].set_title('Linear+Quadratic Approximation Ratio Distribution')\naxes[0,1].legend()\naxes[0,1].grid(True, alpha=0.3)\n\n# Combined histogram for comparison\naxes[1,0].hist(df['ratio_linear'], bins=50, alpha=0.5, color='blue', edgecolor='black', label='Linear')\naxes[1,0].hist(df['ratio_linquad'], bins=50, alpha=0.5, color='green', edgecolor='black', label='LinQuad')\naxes[1,0].axvline(x=1, color='red', linestyle='--', linewidth=2, label='Perfect (ratio=1)')\naxes[1,0].set_xlabel('deltaH_approx / deltaH_true')\naxes[1,0].set_ylabel('Frequency')\naxes[1,0].set_title('Comparison of Approximation Ratios')\naxes[1,0].legend()\naxes[1,0].grid(True, alpha=0.3)\n\n# Box plot comparison by learning rate\neta_labels = [f\"{eta:.0e}\" for eta in sorted(df['eta'].unique())]\nratio_data = [\n    [df[df['eta']==eta]['ratio_linear'].values for eta in sorted(df['eta'].unique())],\n    [df[df['eta']==eta]['ratio_linquad'].values for eta in sorted(df['eta'].unique())]\n]\n\npositions = np.array(range(len(eta_labels)))\nwidth = 0.35\n\nbp1 = axes[1,1].boxplot(ratio_data[0], positions=positions - width/2, widths=width, \n                         patch_artist=True, boxprops=dict(facecolor='lightblue'))\nbp2 = axes[1,1].boxplot(ratio_data[1], positions=positions + width/2, widths=width,\n                         patch_artist=True, boxprops=dict(facecolor='lightgreen'))\n\naxes[1,1].axhline(y=1, color='red', linestyle='--', alpha=0.7, label='Perfect approximation')\naxes[1,1].set_xticks(positions)\naxes[1,1].set_xticklabels(eta_labels, rotation=45)\naxes[1,1].set_xlabel('Learning rate (η)')\naxes[1,1].set_ylabel('deltaH_approx / deltaH_true')\naxes[1,1].set_title('Approximation Ratios by Learning Rate')\naxes[1,1].legend([bp1[\"boxes\"][0], bp2[\"boxes\"][0]], ['Linear', 'LinQuad'])\naxes[1,1].grid(True, alpha=0.3, axis='y')\n\nplt.tight_layout()\nplt.show()\n\n# Statistical summary of ratios\nprint(\"\\nApproximation Ratio Statistics (deltaH_approx/deltaH_true)\")\nprint(\"=\"*60)\nprint(\"\\nLinear Approximation:\")\nprint(f\"  Mean ratio:          {df['ratio_linear'].mean():.3f}\")\nprint(f\"  Median ratio:        {df['ratio_linear'].median():.3f}\")\nprint(f\"  Std deviation:       {df['ratio_linear'].std():.3f}\")\nprint(f\"  25th percentile:     {df['ratio_linear'].quantile(0.25):.3f}\")\nprint(f\"  75th percentile:     {df['ratio_linear'].quantile(0.75):.3f}\")\nprint(f\"  % within 10% of true: {(np.abs(df['ratio_linear'] - 1) < 0.1).mean()*100:.1f}%\")\nprint(f\"  % within 25% of true: {(np.abs(df['ratio_linear'] - 1) < 0.25).mean()*100:.1f}%\")\nprint(f\"  % within 50% of true: {(np.abs(df['ratio_linear'] - 1) < 0.5).mean()*100:.1f}%\")\n\nprint(\"\\nLinear+Quadratic Approximation:\")\nprint(f\"  Mean ratio:          {df['ratio_linquad'].mean():.3f}\")\nprint(f\"  Median ratio:        {df['ratio_linquad'].median():.3f}\")\nprint(f\"  Std deviation:       {df['ratio_linquad'].std():.3f}\")\nprint(f\"  25th percentile:     {df['ratio_linquad'].quantile(0.25):.3f}\")\nprint(f\"  75th percentile:     {df['ratio_linquad'].quantile(0.75):.3f}\")\nprint(f\"  % within 10% of true: {(np.abs(df['ratio_linquad'] - 1) < 0.1).mean()*100:.1f}%\")\nprint(f\"  % within 25% of true: {(np.abs(df['ratio_linquad'] - 1) < 0.25).mean()*100:.1f}%\")\nprint(f\"  % within 50% of true: {(np.abs(df['ratio_linquad'] - 1) < 0.5).mean()*100:.1f}%\")\n\nprint(\"\\nComparison:\")\nprint(f\"  Linear closer to 1.0:   {(np.abs(df['ratio_linear'] - 1) < np.abs(df['ratio_linquad'] - 1)).mean()*100:.1f}% of cases\")\nprint(f\"  LinQuad closer to 1.0:  {(np.abs(df['ratio_linquad'] - 1) < np.abs(df['ratio_linear'] - 1)).mean()*100:.1f}% of cases\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-log plots for each run\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, run_name in enumerate(sorted(df['run'].unique())):\n",
    "    ax = axes[idx]\n",
    "    run_data = df[df['run'] == run_name].sort_values('eta')\n",
    "    \n",
    "    ax.loglog(run_data['eta'], run_data['deltaH_true'], 'ko-', label='True', markersize=6, linewidth=2)\n",
    "    ax.loglog(run_data['eta'], run_data['deltaH_linear'], 'b^--', label='Linear approx', markersize=5, alpha=0.7)\n",
    "    ax.loglog(run_data['eta'], run_data['deltaH_linquad'], 'rs--', label='Lin+Quad approx', markersize=5, alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('η')\n",
    "    ax.set_ylabel('|deltaH|')\n",
    "    ax.set_title(f'{run_name}')\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('deltaH: True vs Approximations (log-log scale)', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined plot with all runs\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Left: All trajectories\n",
    "for run_name in sorted(df['run'].unique()):\n",
    "    run_data = df[df['run'] == run_name].sort_values('eta')\n",
    "    ax1.loglog(run_data['eta'], run_data['deltaH_true'], 'k-', alpha=0.3, linewidth=1)\n",
    "    ax1.loglog(run_data['eta'], run_data['deltaH_linear'], 'b-', alpha=0.2, linewidth=1)\n",
    "    ax1.loglog(run_data['eta'], run_data['deltaH_linquad'], 'r-', alpha=0.2, linewidth=1)\n",
    "\n",
    "# Add mean lines\n",
    "mean_by_eta = df.groupby('eta').agg({\n",
    "    'deltaH_true': 'mean',\n",
    "    'deltaH_linear': 'mean',\n",
    "    'deltaH_linquad': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "ax1.loglog(mean_by_eta['eta'], mean_by_eta['deltaH_true'], 'ko-', label='True (mean)', markersize=8, linewidth=2.5)\n",
    "ax1.loglog(mean_by_eta['eta'], mean_by_eta['deltaH_linear'], 'b^-', label='Linear (mean)', markersize=7, linewidth=2)\n",
    "ax1.loglog(mean_by_eta['eta'], mean_by_eta['deltaH_linquad'], 'rs-', label='LinQuad (mean)', markersize=7, linewidth=2)\n",
    "\n",
    "ax1.set_xlabel('Learning rate (η)')\n",
    "ax1.set_ylabel('|deltaH|')\n",
    "ax1.set_title('All Runs: deltaH Comparison')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Relative errors\n",
    "for run_name in sorted(df['run'].unique()):\n",
    "    run_data = df[df['run'] == run_name].sort_values('eta')\n",
    "    ax2.semilogx(run_data['eta'], run_data['rel_error_linear']*100, 'b-', alpha=0.3, linewidth=1)\n",
    "    ax2.semilogx(run_data['eta'], run_data['rel_error_linquad']*100, 'r-', alpha=0.3, linewidth=1)\n",
    "\n",
    "# Add mean relative errors\n",
    "mean_rel_errors = df.groupby('eta').agg({\n",
    "    'rel_error_linear': 'mean',\n",
    "    'rel_error_linquad': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "ax2.semilogx(mean_rel_errors['eta'], mean_rel_errors['rel_error_linear']*100, 'b^-', \n",
    "             label='Linear (mean)', markersize=7, linewidth=2)\n",
    "ax2.semilogx(mean_rel_errors['eta'], mean_rel_errors['rel_error_linquad']*100, 'rs-', \n",
    "             label='LinQuad (mean)', markersize=7, linewidth=2)\n",
    "\n",
    "ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "ax2.set_xlabel('Learning rate (η)')\n",
    "ax2.set_ylabel('Relative Error (%)')\n",
    "ax2.set_title('Relative Errors in Approximations')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Error Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error histograms\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Absolute errors\n",
    "axes[0,0].hist(df['error_linear'], bins=30, alpha=0.7, color='blue', edgecolor='black', label='Linear')\n",
    "axes[0,0].hist(df['error_linquad'], bins=30, alpha=0.7, color='red', edgecolor='black', label='LinQuad')\n",
    "axes[0,0].set_xlabel('Absolute Error')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].set_title('Distribution of Absolute Errors')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Relative errors (percentage)\n",
    "axes[0,1].hist(df['rel_error_linear']*100, bins=30, alpha=0.7, color='blue', edgecolor='black', label='Linear')\n",
    "axes[0,1].hist(df['rel_error_linquad']*100, bins=30, alpha=0.7, color='red', edgecolor='black', label='LinQuad')\n",
    "axes[0,1].set_xlabel('Relative Error (%)')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "axes[0,1].set_title('Distribution of Relative Errors')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Q-Q plots\n",
    "stats.probplot(df['rel_error_linear'].dropna(), dist=\"norm\", plot=axes[1,0])\n",
    "axes[1,0].set_title('Q-Q Plot: Linear Approximation Errors')\n",
    "\n",
    "stats.probplot(df['rel_error_linquad'].dropna(), dist=\"norm\", plot=axes[1,1])\n",
    "axes[1,1].set_title('Q-Q Plot: LinQuad Approximation Errors')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical moments\n",
    "print(\"Error Distribution Statistics\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nLinear Approximation:\")\n",
    "print(f\"  Mean relative error:     {df['rel_error_linear'].mean()*100:.2f}%\")\n",
    "print(f\"  Std relative error:      {df['rel_error_linear'].std()*100:.2f}%\")\n",
    "print(f\"  Skewness:                {stats.skew(df['rel_error_linear'].dropna()):.3f}\")\n",
    "print(f\"  Kurtosis:                {stats.kurtosis(df['rel_error_linear'].dropna()):.3f}\")\n",
    "\n",
    "print(\"\\nLinear+Quadratic Approximation:\")\n",
    "print(f\"  Mean relative error:     {df['rel_error_linquad'].mean()*100:.2f}%\")\n",
    "print(f\"  Std relative error:      {df['rel_error_linquad'].std()*100:.2f}%\")\n",
    "print(f\"  Skewness:                {stats.skew(df['rel_error_linquad'].dropna()):.3f}\")\n",
    "print(f\"  Kurtosis:                {stats.kurtosis(df['rel_error_linquad'].dropna()):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots of errors by η\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Prepare data for box plots\n",
    "eta_labels = [f\"{eta:.1e}\" for eta in sorted(df['eta'].unique())]\n",
    "linear_errors_by_eta = [df[df['eta']==eta]['rel_error_linear'].values*100 for eta in sorted(df['eta'].unique())]\n",
    "linquad_errors_by_eta = [df[df['eta']==eta]['rel_error_linquad'].values*100 for eta in sorted(df['eta'].unique())]\n",
    "\n",
    "bp1 = ax1.boxplot(linear_errors_by_eta, labels=eta_labels, patch_artist=True)\n",
    "for patch in bp1['boxes']:\n",
    "    patch.set_facecolor('lightblue')\n",
    "ax1.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "ax1.set_xlabel('Learning rate (η)')\n",
    "ax1.set_ylabel('Relative Error (%)')\n",
    "ax1.set_title('Linear Approximation Errors by η')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "bp2 = ax2.boxplot(linquad_errors_by_eta, labels=eta_labels, patch_artist=True)\n",
    "for patch in bp2['boxes']:\n",
    "    patch.set_facecolor('lightcoral')\n",
    "ax2.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "ax2.set_xlabel('Learning rate (η)')\n",
    "ax2.set_ylabel('Relative Error (%)')\n",
    "ax2.set_title('Linear+Quadratic Approximation Errors by η')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Error Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error vs eta_star correlation\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Linear approx error vs eta_star\n",
    "axes[0,0].scatter(df['eta_star'], df['rel_error_linear']*100, alpha=0.5, color='blue')\n",
    "axes[0,0].set_xlabel('η* (optimal learning rate)')\n",
    "axes[0,0].set_ylabel('Linear Approx Relative Error (%)')\n",
    "axes[0,0].set_title('Linear Approximation Error vs η*')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# LinQuad approx error vs eta_star\n",
    "axes[0,1].scatter(df['eta_star'], df['rel_error_linquad']*100, alpha=0.5, color='red')\n",
    "axes[0,1].set_xlabel('η* (optimal learning rate)')\n",
    "axes[0,1].set_ylabel('LinQuad Approx Relative Error (%)')\n",
    "axes[0,1].set_title('LinQuad Approximation Error vs η*')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Error vs log(eta)\n",
    "axes[1,0].scatter(np.log10(df['eta']), df['rel_error_linear']*100, alpha=0.5, color='blue', label='Linear')\n",
    "axes[1,0].scatter(np.log10(df['eta']), df['rel_error_linquad']*100, alpha=0.5, color='red', label='LinQuad')\n",
    "axes[1,0].set_xlabel('log₁₀(η)')\n",
    "axes[1,0].set_ylabel('Relative Error (%)')\n",
    "axes[1,0].set_title('Error vs Learning Rate (log scale)')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "axes[1,0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Error improvement vs eta\n",
    "improvement = (np.abs(df['rel_error_linear']) - np.abs(df['rel_error_linquad'])) * 100\n",
    "axes[1,1].scatter(np.log10(df['eta']), improvement, alpha=0.5, color='green')\n",
    "axes[1,1].set_xlabel('log₁₀(η)')\n",
    "axes[1,1].set_ylabel('Error Improvement (%)')\n",
    "axes[1,1].set_title('Quadratic Correction Improvement\\n(Positive = LinQuad better)')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "axes[1,1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation coefficients\n",
    "print(\"\\nCorrelation Analysis\")\n",
    "print(\"=\"*50)\n",
    "valid_mask = ~df['eta_star'].isna()\n",
    "if valid_mask.sum() > 0:\n",
    "    corr_linear_etastar = df.loc[valid_mask, 'rel_error_linear'].corr(df.loc[valid_mask, 'eta_star'])\n",
    "    corr_linquad_etastar = df.loc[valid_mask, 'rel_error_linquad'].corr(df.loc[valid_mask, 'eta_star'])\n",
    "    print(f\"Correlation(Linear Error, η*):   {corr_linear_etastar:.3f}\")\n",
    "    print(f\"Correlation(LinQuad Error, η*):  {corr_linquad_etastar:.3f}\")\n",
    "\n",
    "corr_linear_eta = df['rel_error_linear'].corr(df['eta'])\n",
    "corr_linquad_eta = df['rel_error_linquad'].corr(df['eta'])\n",
    "print(f\"\\nCorrelation(Linear Error, η):    {corr_linear_eta:.3f}\")\n",
    "print(f\"Correlation(LinQuad Error, η):   {corr_linquad_eta:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Approximation Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate quality metrics for each run and overall\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "quality_metrics = []\n",
    "\n",
    "for run_name in sorted(df['run'].unique()):\n",
    "    run_data = df[df['run'] == run_name]\n",
    "    \n",
    "    metrics = {\n",
    "        'run': run_name,\n",
    "        'r2_linear': r2_score(run_data['deltaH_true'], run_data['deltaH_linear']),\n",
    "        'r2_linquad': r2_score(run_data['deltaH_true'], run_data['deltaH_linquad']),\n",
    "        'rmse_linear': np.sqrt(mean_squared_error(run_data['deltaH_true'], run_data['deltaH_linear'])),\n",
    "        'rmse_linquad': np.sqrt(mean_squared_error(run_data['deltaH_true'], run_data['deltaH_linquad'])),\n",
    "        'mae_linear': mean_absolute_error(run_data['deltaH_true'], run_data['deltaH_linear']),\n",
    "        'mae_linquad': mean_absolute_error(run_data['deltaH_true'], run_data['deltaH_linquad'])\n",
    "    }\n",
    "    quality_metrics.append(metrics)\n",
    "\n",
    "# Overall metrics\n",
    "overall_metrics = {\n",
    "    'run': 'OVERALL',\n",
    "    'r2_linear': r2_score(df['deltaH_true'], df['deltaH_linear']),\n",
    "    'r2_linquad': r2_score(df['deltaH_true'], df['deltaH_linquad']),\n",
    "    'rmse_linear': np.sqrt(mean_squared_error(df['deltaH_true'], df['deltaH_linear'])),\n",
    "    'rmse_linquad': np.sqrt(mean_squared_error(df['deltaH_true'], df['deltaH_linquad'])),\n",
    "    'mae_linear': mean_absolute_error(df['deltaH_true'], df['deltaH_linear']),\n",
    "    'mae_linquad': mean_absolute_error(df['deltaH_true'], df['deltaH_linquad'])\n",
    "}\n",
    "quality_metrics.append(overall_metrics)\n",
    "\n",
    "df_metrics = pd.DataFrame(quality_metrics)\n",
    "\n",
    "print(\"Approximation Quality Metrics\")\n",
    "print(\"=\"*80)\n",
    "print(df_metrics.to_string(index=False))\n",
    "\n",
    "# Visualize R² scores\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(df_metrics) - 1)  # Exclude OVERALL for the plot\n",
    "width = 0.35\n",
    "\n",
    "metrics_plot = df_metrics[df_metrics['run'] != 'OVERALL']\n",
    "ax.bar(x - width/2, metrics_plot['r2_linear'], width, label='Linear', color='blue', alpha=0.7)\n",
    "ax.bar(x + width/2, metrics_plot['r2_linquad'], width, label='LinQuad', color='red', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Run')\n",
    "ax.set_ylabel('R² Score')\n",
    "ax.set_title('R² Scores: Linear vs LinQuad Approximations')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics_plot['run'])\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Quadratic Correction Effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze where quadratic correction helps most\n",
    "df['abs_error_linear'] = np.abs(df['error_linear'])\n",
    "df['abs_error_linquad'] = np.abs(df['error_linquad'])\n",
    "df['quadratic_helps'] = df['abs_error_linquad'] < df['abs_error_linear']\n",
    "\n",
    "# Summary by η\n",
    "effectiveness = df.groupby('eta').agg({\n",
    "    'quadratic_helps': 'mean',  # Fraction where quadratic helps\n",
    "    'abs_error_linear': 'mean',\n",
    "    'abs_error_linquad': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "effectiveness['improvement_ratio'] = (effectiveness['abs_error_linear'] - effectiveness['abs_error_linquad']) / effectiveness['abs_error_linear']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Fraction where quadratic helps\n",
    "ax1.bar(range(len(effectiveness)), effectiveness['quadratic_helps']*100, color='green', alpha=0.7)\n",
    "ax1.set_xlabel('Learning rate (η)')\n",
    "ax1.set_ylabel('% of runs where LinQuad beats Linear')\n",
    "ax1.set_title('Quadratic Correction Effectiveness by η')\n",
    "ax1.set_xticks(range(len(effectiveness)))\n",
    "ax1.set_xticklabels([f\"{eta:.1e}\" for eta in effectiveness['eta']], rotation=45)\n",
    "ax1.axhline(y=50, color='red', linestyle='--', alpha=0.5)\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Average improvement\n",
    "ax2.bar(range(len(effectiveness)), effectiveness['improvement_ratio']*100, \n",
    "        color=['green' if x > 0 else 'red' for x in effectiveness['improvement_ratio']], alpha=0.7)\n",
    "ax2.set_xlabel('Learning rate (η)')\n",
    "ax2.set_ylabel('Average % Improvement')\n",
    "ax2.set_title('Average Error Reduction from Quadratic Correction')\n",
    "ax2.set_xticks(range(len(effectiveness)))\n",
    "ax2.set_xticklabels([f\"{eta:.1e}\" for eta in effectiveness['eta']], rotation=45)\n",
    "ax2.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nQuadratic Correction Effectiveness Summary\")\n",
    "print(\"=\"*60)\n",
    "for _, row in effectiveness.iterrows():\n",
    "    print(f\"η = {row['eta']:.1e}:\")\n",
    "    print(f\"  LinQuad better in {row['quadratic_helps']*100:.1f}% of runs\")\n",
    "    print(f\"  Average improvement: {row['improvement_ratio']*100:.1f}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary analysis\n",
    "print(\"SUMMARY AND RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find optimal η ranges\n",
    "low_error_threshold = 0.5  # 50% relative error threshold\n",
    "\n",
    "linear_good_etas = df.groupby('eta')['rel_error_linear'].apply(lambda x: np.abs(x).mean() < low_error_threshold)\n",
    "linquad_good_etas = df.groupby('eta')['rel_error_linquad'].apply(lambda x: np.abs(x).mean() < low_error_threshold)\n",
    "\n",
    "print(\"\\n1. OPTIMAL η RANGES:\")\n",
    "print(f\"   Linear approximation works well (< {low_error_threshold*100}% avg error) for:\")\n",
    "good_linear = linear_good_etas[linear_good_etas].index.tolist()\n",
    "if good_linear:\n",
    "    print(f\"   η ∈ [{min(good_linear):.1e}, {max(good_linear):.1e}]\")\n",
    "else:\n",
    "    print(\"   No η values meet this criterion\")\n",
    "\n",
    "print(f\"\\n   LinQuad approximation works well (< {low_error_threshold*100}% avg error) for:\")\n",
    "good_linquad = linquad_good_etas[linquad_good_etas].index.tolist()\n",
    "if good_linquad:\n",
    "    print(f\"   η ∈ [{min(good_linquad):.1e}, {max(good_linquad):.1e}]\")\n",
    "else:\n",
    "    print(\"   No η values meet this criterion\")\n",
    "\n",
    "print(\"\\n2. ERROR CHARACTERISTICS:\")\n",
    "print(f\"   - Errors appear to be {'normally' if abs(stats.skew(df['rel_error_linear'].dropna())) < 1 else 'non-normally'} distributed\")\n",
    "print(f\"   - Linear approx has {'positive' if df['error_linear'].mean() > 0 else 'negative'} bias on average\")\n",
    "print(f\"   - LinQuad approx has {'positive' if df['error_linquad'].mean() > 0 else 'negative'} bias on average\")\n",
    "\n",
    "print(\"\\n3. VARIANCE ANALYSIS:\")\n",
    "cv_linear = df.groupby('eta').apply(lambda x: x['deltaH_linear'].std() / x['deltaH_linear'].mean())\n",
    "cv_linquad = df.groupby('eta').apply(lambda x: x['deltaH_linquad'].std() / x['deltaH_linquad'].mean())\n",
    "print(f\"   Mean coefficient of variation:\")\n",
    "print(f\"   - Linear:  {cv_linear.mean():.3f}\")\n",
    "print(f\"   - LinQuad: {cv_linquad.mean():.3f}\")\n",
    "\n",
    "print(\"\\n4. WHEN TO USE EACH APPROXIMATION:\")\n",
    "crossover_eta = effectiveness[effectiveness['improvement_ratio'] > 0]['eta'].min() if any(effectiveness['improvement_ratio'] > 0) else None\n",
    "if crossover_eta:\n",
    "    print(f\"   - Use Linear for η < {crossover_eta:.1e}\")\n",
    "    print(f\"   - Use LinQuad for η ≥ {crossover_eta:.1e}\")\n",
    "else:\n",
    "    print(\"   - Linear approximation generally performs better across all η\")\n",
    "\n",
    "print(\"\\n5. KEY INSIGHTS:\")\n",
    "if df['eta_star'].notna().any():\n",
    "    if abs(df['rel_error_linear'].corr(df['eta_star'])) > 0.3:\n",
    "        print(f\"   - Error correlates with η* (r={df['rel_error_linear'].corr(df['eta_star']):.3f})\")\n",
    "    else:\n",
    "        print(\"   - Error shows weak correlation with η*\")\n",
    "\n",
    "print(f\"   - Approximations are most reliable in mid-range η values\")\n",
    "print(f\"   - High variance suggests need for multiple runs for reliable estimates\")\n",
    "print(f\"   - Quadratic correction most beneficial at large η (> 1e-5)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}