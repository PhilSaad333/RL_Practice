# ðŸŽ¯ Single Run Configuration
# For individual entropy probe tests
# Optimized for quick testing and debugging

# Core batch configuration - single test focused
batch_config:
  B_E_values: [256]                    # Will be overridden by --be argument
  B_U: 32                              # Will be overridden by --bu argument
  runs_per_batch: 1                    # Single run
  G: 8                                 # Standard generations
  rollout_batch_size: 32               # Balanced batch size
  dataset_name: "gsm8k_r1_template"
  split: "train"

# Probe computation mode
probe_config:
  mode: "exact"
  M: null

# Probe analysis - focus on conditional variance for single tests
probe_rework:
  mb_size_prompts: 2                   # Memory-efficient
  buffers_dtype: "float32"
  weighting_mode: "dr_grpo"
  conditional_variance_batch_size: 6   # Efficient batching
  
  # Single tests focus on the new conditional variance estimator
  compute_vx_vy_variance: false
  compute_conditional_variance: true   # Primary focus
  compute_importance_sampling: false   # Skip expensive operations
  
  ddp_allreduce: false
  master_seed: 42

# Single-GPU settings
distributed:
  find_unused_parameters: false
  reduce_dtype: "float32"
  barriers: false

# Importance sampling disabled for speed
importance:
  enabled: false

importance_sampling:
  use_snis: true
  use_psis: false  
  ess_threshold: 0.5
  resample_on_low_ess: false

# Statistics configuration
stats_config:
  compute_plugin_se: true
  compute_jackknife_se: false          # Skip expensive jackknife for single runs

# Memory settings - optimized for single runs
memory_config:
  microbatch_size: 2
  teacher_force_microbatch_size: 2
  amp: true
  dtype: "bfloat16"

learning_rate: 2e-6

checkpoint:
  checkpoint_path: ""
  optimizer_path: ""
  model_config_path: "Qwen/Qwen2.5-1.5B"

generation:
  max_new_tokens: 50
  temperature: 1.0
  top_p: 1.0
  do_sample: true
  pad_token_id: null

output:
  save_results: true
  results_path: ""
  log_level: "INFO"
  save_samples: false