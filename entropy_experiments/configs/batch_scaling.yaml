# üîç Batch Scaling Test Configuration
# For testing Œ¥H‚ÇÅ convergence vs 1/B_E scaling patterns
# Tests multiple B_E values with fixed B_U

# Core batch configuration - CLEAN: removed confusing "B" parameter!
batch_config:
  B_E_values: [16, 32, 64, 128]        # ‚úÖ Support lists for scaling tests!
  B_U: 32                              # ‚úÖ Clear, usually fixed
  runs_per_batch: 3                    # ‚úÖ Clear repetition control
  G: 8                                 # Generations per prompt
  rollout_batch_size: 32               # GPU-efficient batch size
  dataset_name: "gsm8k_r1_template"    # Standard dataset
  split: "train"

# Probe computation mode
probe_config:
  mode: "exact"                        # Use exact computation (not sampling)
  M: null                              # Not used for exact mode

# Probe analysis configuration - focus on conditional variance
probe_rework:
  mb_size_prompts: 2                   # Memory-efficient microbatch size
  buffers_dtype: "float32"             # Precision for gradients
  weighting_mode: "dr_grpo"            # Standard weighting
  
  # Focus on NEW conditional variance estimator (the one we're testing!)
  compute_vx_vy_variance: false        # Turn OFF old V_X + V_Y estimator
  compute_conditional_variance: true   # Turn ON new V_E|U estimator  
  compute_importance_sampling: false   # Turn OFF expensive importance sampling
  
  ddp_allreduce: false                 # Single GPU mode
  master_seed: 42                      # Deterministic for reproducibility

# Single-GPU distributed settings
distributed:
  find_unused_parameters: false       # Single GPU
  reduce_dtype: "float32"              # Standard precision
  barriers: false                      # No need for barriers

# Importance sampling (disabled for conditional variance focus)
importance:
  enabled: false                       # Disable expensive Stage 2

importance_sampling:
  use_snis: true
  use_psis: false
  ess_threshold: 0.5
  resample_on_low_ess: false

# Statistics configuration
stats_config:
  compute_plugin_se: true              # Enable standard error computation
  compute_jackknife_se: false          # Disable expensive jackknife

# Memory settings - balanced for scaling tests
memory_config:
  microbatch_size: 2                   # Small for memory efficiency
  teacher_force_microbatch_size: 2     # Match microbatch size
  amp: true                            # Enable automatic mixed precision
  dtype: "bfloat16"                    # Memory-efficient dtype

# Learning rate - from actual RL training
learning_rate: 2e-6                   # Match your RL training setup

# Checkpoint configuration (will be auto-filled by runner)
checkpoint:
  checkpoint_path: ""                  # Auto-filled from --checkpoint argument
  optimizer_path: ""                   # Auto-determined from checkpoint path
  model_config_path: "Qwen/Qwen2.5-1.5B"  # Base model

# Generation settings for response sampling
generation:
  max_new_tokens: 50                   # Short responses for fast testing
  temperature: 0.7
  top_p: 1.0
  do_sample: true
  pad_token_id: null

# Output configuration (auto-managed by runner)
output:
  save_results: true                   # Always save results
  results_path: ""                     # Auto-generated by runner
  log_level: "INFO"                    # Will be overridden by --verbose/--quiet
  save_samples: false                  # Don't save individual responses