# Ultra-minimal debug config for scaling analysis - single H100
# Designed to run fast and capture detailed logging of the scaling issue

# Core sampling parameters - tiny for fast debugging
batch_config:
  B: 4                               # Minimal batch size 
  B_E: 4                             # Small evaluation batch  
  B_U: 4                             # Small update batch
  G: 2                               # Few generations per prompt
  rollout_batch_size: 2              # Minimal rollout batch
  dataset_name: "gsm8k_r1_template" 
  split: "train"

# Probe computation mode
probe_config:
  mode: "exact"                      # Use exact computation
  M: null                            

# NEW: Test conditional variance estimator only
probe_rework:
  mb_size_prompts: 2                 # Very small microbatch for detailed logging
  buffers_dtype: "float32"           
  weighting_mode: "dr_grpo"          
  
  # Test ONLY the new conditional variance estimator
  compute_vx_vy_variance: false      # Turn OFF original V_X + V_Y 
  compute_conditional_variance: true # Turn ON new V_E|U estimator
  compute_importance_sampling: false # Turn OFF expensive importance sampling
  
  ddp_allreduce: false               # Disable for single GPU
  master_seed: 42                    

# Single-GPU settings
distributed:
  find_unused_parameters: false     # Single GPU
  reduce_dtype: "float32"           
  barriers: false                   

# Stage 2 Importance Sampling Configuration (disabled)
importance:
  enabled: false                    # Disable Stage 2 two-batch ground-truth
  is_mode: "snis"                   
  clip_c: 10.0                      
  training_loss: "rl"               
  rl_grad_accum: 1                  
  snapshot_device: "cpu"            
  importance_microbatch_size: 2     
  report_per_token: false           

# Importance sampling details
importance_sampling:
  use_snis: true                    
  use_psis: false                   
  ess_threshold: 0.5                
  resample_on_low_ess: false        

# Statistics configuration
stats_config:
  compute_plugin_se: true           
  compute_jackknife_se: false       

# Memory settings - minimal for debugging
memory_config:
  microbatch_size: 2                 # Small for debugging
  teacher_force_microbatch_size: 2   # Small for debugging
  amp: true                          
  dtype: "bfloat16"                  

# Learning rate - TEST BOTH VALUES
learning_rate: 2e-6                  # Start with small value for baseline

# Use our step_40 checkpoint with optimizer states
checkpoint:
  checkpoint_path: "/home/ubuntu/localfs/stage3_checkpoints/step_40"
  optimizer_path: "/home/ubuntu/localfs/stage3_checkpoints/step_40/optimizer.pt"
  model_config_path: "Qwen/Qwen2.5-1.5B"

# Generation settings
generation:
  max_new_tokens: 50                 # Short for quick test
  temperature: 0.7
  top_p: 1.0
  do_sample: true
  pad_token_id: null

# Output settings
output:
  save_results: true
  results_path: "debug_scaling_results.json"
  log_level: "DEBUG"                # Enable debug logging
  save_samples: false