# Stage 3 Multi-GPU Mixed E/U Batch Probe Configuration
# Optimized for 2×H100 80GB GPUs with deterministic sampling

# Core sampling parameters - H100-optimized for high utilization
batch_config:
  B: 128                             # Base batch size (for ProbeComponents)
  B_E: 128                           # Evaluation batch size (64 per GPU)
  B_U: 128                           # Update batch size (64 per GPU)  
  G: 8                               # Generations per prompt
  rollout_batch_size: 256            # Larger batches for H100s
  dataset_name: "gsm8k_r1_template" 
  split: "train"

# Probe computation mode
probe_config:
  mode: "exact"                      # Use exact computation (not blocks)
  M: null                            # Not used for exact mode

# Stage 1+2+3 Mixed Probe Configuration
probe_rework:
  mb_size_prompts: 4                 # Microbatch size (prompts per microbatch) - increased for H100
  buffers_dtype: "float32"           # Buffer precision (keep fp32 for stability)
  weighting_mode: "dr_grpo"          # Weighting mode
  variance_enabled: true             # Enable Stage 2 variance computation
  ddp_allreduce: true                # Enable DDP all-reduce
  master_seed: 42                    # Deterministic seed for multi-GPU consistency

# Stage 3 Multi-GPU specific settings
distributed:
  find_unused_parameters: true      # Required for DDP compatibility
  reduce_dtype: "float32"           # Standard precision for reductions
  barriers: true                    # Insert barriers for profiling

# Stage 2 Importance Sampling Configuration  
importance:
  enabled: true                     # Enable Stage 2 two-batch ground-truth
  is_mode: "snis"                   # Self-normalized importance sampling
  clip_c: 10.0                      # Clipping constant (unused for SNIS)
  training_loss: "rl"               # Use RL-aligned training loss (was "nll")
  rl_grad_accum: 1                  # RL gradient accumulation steps
  snapshot_device: "cpu"            # CPU snapshots to save VRAM
  importance_microbatch_size: 1     # Conservative for stability
  report_per_token: false           # Disable for faster computation

# Importance sampling details
importance_sampling:
  use_snis: true                    # Use self-normalized importance sampling
  use_psis: false                   # Don't use Pareto-smoothed importance sampling
  ess_threshold: 0.5                # Effective sample size threshold
  resample_on_low_ess: false        # Don't resample on low ESS

# Statistics configuration
stats_config:
  compute_plugin_se: true           # Compute plug-in variance estimates
  compute_jackknife_se: false       # Skip jackknife (computationally expensive)

# Memory and performance - H100 optimized for high utilization
memory_config:
  microbatch_size: 4                # Larger microbatches for H100 high utilization
  teacher_force_microbatch_size: 8  # Larger G-microbatches  
  amp: true                         # Use automatic mixed precision
  dtype: "bfloat16"                 # H100-optimized precision

# Learning rate - used consistently throughout probe computation
learning_rate: 2e-6

# Use extracted checkpoint path (will be updated after extraction)
checkpoint:
  checkpoint_path: "TBD_AFTER_EXTRACTION"
  optimizer_path: "TBD_AFTER_EXTRACTION"
  model_config_path: "Qwen/Qwen2.5-1.5B"

# Generation settings - increased for better probe signal
generation:
  max_new_tokens: 200
  temperature: 0.7
  top_p: 1.0
  do_sample: true
  pad_token_id: null

# Output and logging  
output:
  save_results: true
  results_path: "stage3_multigpu_probe_results.json"
  log_level: "INFO"
  save_samples: false

# Advanced options
advanced:
  force_recompute: true
  validation_mode: false
  profile_memory: true
  profile_timing: true

# Stage 3 Acceptance Criteria Notes:
# - Deterministic E/U indices across ranks
# - Identical μ_X/μ_Y buffers on all GPUs  
# - Consistent bars_dot without extra reduction
# - Correct global batch sizes (B_E_global=32, B_U_global=32)
# - No-sync during probe phases, normal sync during training step
# - All results computed with multi-GPU coordination